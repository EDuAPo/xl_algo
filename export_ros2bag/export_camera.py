#!/usr/bin/env python3

# -*- coding: utf-8 -*-

import argparse
from datetime import datetime
import os
from pathlib import Path
import threading
import queue
import sys
from concurrent.futures import ThreadPoolExecutor

import cv2
import gi
import numpy as np
import time  # ç”¨äºæ—¶é—´æˆ³fallbackå’Œæ€§èƒ½ç›‘æ§
from datetime import datetime as dt_datetime  # ç”¨äºæ€§èƒ½ç»Ÿè®¡

from rosbags.highlevel import AnyReader
from rosbags.serde import deserialize_cdr

gi.require_version('Gst', '1.0')
from gi.repository import Gst, GLib

Gst.init(None)


ALL_CAMERA_H265_TOPICS = [
    '/camera/cam_8M_wa_front',
    '/camera/cam_8M_pt_front',
    '/camera/cam_3M_front',
    '/camera/cam_3M_left',
    '/camera/cam_3M_right',
    '/camera/cam_3M_rear',
]

def create_pipeline(topic_name_sanitized, use_hw_accel="auto"):
    """
    ä¸ºæ¯ä¸ªtopicåˆ›å»ºä¸€ä¸ªGStreamerè§£ç ç®¡é“ã€‚
    use_hw_accel: 'nvidia', 'vaapi', or 'none'
    """
    # è½¯ä»¶è§£ç ï¼ˆé»˜è®¤å’Œå¤‡ç”¨é€‰é¡¹ï¼‰
    decoder = "avdec_h265"
    
    # å°è¯•é€‰æ‹©ç¡¬ä»¶è§£ç å™¨
    if use_hw_accel == "nvidia":
        # æ³¨æ„: NVIDIAç®¡é“å¯èƒ½éœ€è¦æ›´å¤æ‚çš„å…ƒç´ ï¼Œå¦‚nvvidconv
        # è¿™åªæ˜¯ä¸€ä¸ªåŸºç¡€ç¤ºä¾‹ï¼Œå¯èƒ½éœ€è¦æ ¹æ®å…·ä½“é©±åŠ¨å’ŒGStreamerç‰ˆæœ¬å¾®è°ƒ
        decoder = "nvv4l2decoder"
        print(f"[{topic_name_sanitized}] Using NVIDIA hardware decoder.")
    elif use_hw_accel == "vaapi":
        decoder = "vaapih265dec"
        print(f"[{topic_name_sanitized}] Using VA-API hardware decoder.")
    else:
        print(f"[{topic_name_sanitized}] Using software decoder (avdec_h265).")

    pipeline_str = (
        f"appsrc name={topic_name_sanitized} format=time stream-type=stream caps=video/x-h265,stream-format=byte-stream,alignment=au ! "
        f"h265parse config-interval=1 ! {decoder} ! "
        "videoconvert ! video/x-raw,format=BGR ! "
        "appsink name=sink emit-signals=True max-buffers=1000 drop=True sync=false"
    )
    return Gst.parse_launch(pipeline_str)

def save_image_task(filepath, frame):
    """ç”¨äºåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œçš„å›¾åƒä¿å­˜ä»»åŠ¡"""
    cv2.imwrite(filepath, frame)

def on_new_sample(sink, user_data):
    """appsinkçš„å›è°ƒå‡½æ•°ï¼Œç°åœ¨å°†ä¿å­˜ä»»åŠ¡æäº¤ç»™çº¿ç¨‹æ± """
    output_dir, topic_name, counters, writer_pool = user_data  # ç§»é™¤timestamps

    sample = sink.emit('pull-sample')
    if not sample: return Gst.FlowReturn.OK

    buf, caps = sample.get_buffer(), sample.get_caps()
    height = caps.get_structure(0).get_value('height')
    width = caps.get_structure(0).get_value('width')

    result, mapinfo = buf.map(Gst.MapFlags.READ)
    if result:
        try:
            timestamp = buf.pts  # ä»PTSè·å–timestamp
            if timestamp == Gst.CLOCK_TIME_NONE:
                # Fallback: å¦‚æœPTSæ— æ•ˆï¼Œç”¨å½“å‰ç³»ç»Ÿæ—¶é—´ï¼ˆçº³ç§’ï¼‰
                print(f"\n[{topic_name}] Warning: Invalid PTS, using current time.")
                timestamp = int(time.time_ns())  # éœ€è¦import time

            sec, nsec = timestamp // 1_000_000_000, timestamp % 1_000_000_000
            timestamp_sec = timestamp / 1e9
            dt = datetime.fromtimestamp(timestamp_sec)
            timestamp_str = dt.strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ç²¾ç¡®åˆ°æ¯«ç§’

            filename = f"{timestamp_str}.jpg"
            filepath = os.path.join(output_dir, filename)
            
            frame = np.ndarray((height, width, 3), buffer=mapinfo.data, dtype=np.uint8)
            
            # å¼‚æ­¥å†™å…¥ï¼Œå¿…é¡»å¤åˆ¶frame
            writer_pool.submit(save_image_task, filepath, frame.copy())
            
            counters['decoded'] += 1
            if counters['decoded'] % 50 == 0:  # ä¼˜åŒ–ï¼šæ¯50å¸§æ‰“å°ä¸€æ¬¡
                current_time = time.time()
                elapsed = current_time - counters['start_time']
                interval = current_time - counters['last_print_time']
                frames_in_interval = counters['decoded'] - counters['last_decoded_count']
                
                # è®¡ç®—é€Ÿç‡
                overall_fps = counters['decoded'] / elapsed if elapsed > 0 else 0
                interval_fps = frames_in_interval / interval if interval > 0 else 0
                
                print(f"\r[{topic_name}] å·²è§£ç : {counters['decoded']} å¸§ | "
                      f"æ€»é€Ÿç‡: {overall_fps:.2f} fps | "
                      f"å½“å‰é€Ÿç‡: {interval_fps:.2f} fps | "
                      f"æ€»è€—æ—¶: {elapsed:.1f}s", end='')
                
                counters['last_print_time'] = current_time
                counters['last_decoded_count'] = counters['decoded']
        except Exception as e:  # é€šç”¨æ•è·ï¼Œæ›¿æ¢åŸEmptyå¼‚å¸¸
            print(f"\n[{topic_name}] Error in callback: {e}", file=sys.stderr)
        finally:
            buf.unmap(mapinfo)
    return Gst.FlowReturn.OK

def decode_worker(topic_name, data_queue, base_output_dir, hw_accel_flag):
    """è§£ç å·¥ä½œçº¿ç¨‹ï¼Œç°åœ¨åŒ…å«ä¸€ä¸ªç”¨äºå†™å…¥çš„çº¿ç¨‹æ± """
    topic_name_sanitized = topic_name.replace('/', '_')
    topic_name_sanitized = topic_name_sanitized.lstrip('_')
    output_dir = os.path.join(base_output_dir, topic_name_sanitized)
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"[{topic_name}] Worker started. Outputting to: {output_dir}")

    main_loop = GLib.MainLoop()
    counters = {
        'pushed': 0, 
        'decoded': 0,
        'start_time': time.time(),  # æ€§èƒ½ç›‘æ§ï¼šå¼€å§‹æ—¶é—´
        'last_print_time': time.time(),  # æ€§èƒ½ç›‘æ§ï¼šä¸Šæ¬¡æ‰“å°æ—¶é—´
        'last_decoded_count': 0  # æ€§èƒ½ç›‘æ§ï¼šä¸Šæ¬¡è§£ç æ•°é‡
    }
    # åˆ›å»ºä¸€ä¸ªæœ€å¤šæœ‰12ä¸ªçº¿ç¨‹çš„å†™å…¥æ± ï¼Œé™åˆ¶é˜Ÿåˆ—å¤§å°é˜²æ­¢å†…å­˜æ³„æ¼
    from concurrent.futures import ThreadPoolExecutor
    import threading
    writer_pool = ThreadPoolExecutor(max_workers=12, thread_name_prefix="ImgWriter")
    
    pipeline = create_pipeline(topic_name_sanitized, hw_accel_flag)
    
    user_data_for_callback = (output_dir, topic_name, counters, writer_pool)  # ç§»é™¤timestamps
    sink = pipeline.get_by_name('sink')
    sink.connect("new-sample", on_new_sample, user_data_for_callback)

    bus = pipeline.get_bus()
    bus.add_signal_watch()
    def on_bus_message(bus, message):
        t = message.type
        if t == Gst.MessageType.EOS:
            print(f"\n[{topic_name}] Received EOS from pipeline.")
            main_loop.quit()
        elif t == Gst.MessageType.ERROR:
            err, debug = message.parse_error()
            print(f"\n[{topic_name}] GStreamer Error: {err}. {debug}", file=sys.stderr)
            main_loop.quit()
        return True
    bus.connect("message", on_bus_message)

    appsrc = pipeline.get_by_name(topic_name_sanitized)
    appsrc.set_property('is-live', False)
    appsrc.set_property('max-bytes', 10485760)  # ä¼˜åŒ–ï¼š10MBç¼“å†²åŒºï¼Œå‡å°‘å†…å­˜ç¢ç‰‡
    appsrc.set_property('block', True)   # push-buffer é˜»å¡ç›´åˆ°æ¶ˆè´¹
    appsrc.set_property('format', Gst.Format.TIME)
    appsrc.set_property('emit-signals', True)

    pipeline.set_state(Gst.State.PLAYING)
    loop_thread = threading.Thread(target=main_loop.run, daemon=True)
    loop_thread.start()

    try:
        while True:
            item = data_queue.get()
            if item is None: break
            
            timestamp, h265_data = item
            counters['pushed'] += 1
            buf = Gst.Buffer.new_wrapped(h265_data)
            buf.pts = timestamp  # è®¾ç½®PTSï¼ˆçº³ç§’å•ä½ï¼Œç›´æ¥èµ‹å€¼ï¼‰
            buf.dts = Gst.CLOCK_TIME_NONE  # å¯é€‰ï¼šdecode timestampï¼Œé€šå¸¸ä¸éœ€è®¾ç½®
            appsrc.emit('push-buffer', buf)
    except Exception as e:
        print(f"[{topic_name}] Error in push loop: {e}", file=sys.stderr)

    print(f"[{topic_name}] Sending EOS to appsrc...")
    appsrc.emit('end-of-stream')

    print(f"[{topic_name}] Waiting for pipeline to finish (max 10s)...")
    loop_thread.join(timeout=10.0)

    if loop_thread.is_alive():
        print(f"[{topic_name}] Pipeline did not exit in time. Forcing quit...")
        main_loop.quit()
        loop_thread.join(timeout=2.0)

    # ç­‰å¾…æ‰€æœ‰å†™å…¥ä»»åŠ¡å®Œæˆ
    writer_pool.shutdown(wait=True)

    pipeline.set_state(Gst.State.NULL)
    
    total_time = time.time() - counters['start_time']
    avg_fps = counters['decoded'] / total_time if total_time > 0 else 0
    
    print(f"\r[{topic_name}] Finalizing...")
    print(f"\n{'='*60}")
    print(f"ğŸ“Š æ€§èƒ½ç»Ÿè®¡ - Topic: {topic_name}")
    print(f"{'='*60}")
    print(f"  æ¨é€å¸§æ•°: {counters['pushed']}")
    print(f"  è§£ç æˆåŠŸ: {counters['decoded']}")
    print(f"  æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"  å¹³å‡é€Ÿç‡: {avg_fps:.2f} fps")
    print(f"  å¹³å‡æ¯å¸§: {1000/avg_fps:.2f} ms" if avg_fps > 0 else "  å¹³å‡æ¯å¸§: N/A")
    print(f"{'='*60}")

def get_all_bags(input_path):
    """è·å–æ‰€æœ‰bagç›®å½•ï¼Œæ”¯æŒå•ç›®å½•å’Œå¤šç›®å½•æ¨¡å¼"""
    bag_root = os.path.abspath(input_path)
    bag_paths = []
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„æœ¬èº«æ˜¯å¦æ˜¯ä¸€ä¸ªbagç›®å½•ï¼ˆåŒ…å«metadata.yamlï¼‰
    meta_file = os.path.join(bag_root, "metadata.yaml")
    if os.path.exists(meta_file):
        print(f"âœ… è¾“å…¥è·¯å¾„æ˜¯å•ä¸ªbagç›®å½•ï¼š{bag_root}")
        bag_paths.append(Path(bag_root))
        return bag_paths
    
    # å¦åˆ™ï¼ŒæŒ‰åŸé€»è¾‘éå†å­ç›®å½•
    print(f"ğŸ“ æŒ‰å¤šç›®å½•æ¨¡å¼å¤„ç†ï¼šéå† {bag_root} çš„å­ç›®å½•")
    for entry in sorted(os.listdir(bag_root)):
        bag_path = os.path.join(bag_root, entry)
        if not os.path.isdir(bag_path):
            continue
        
        meta_file = os.path.join(bag_path, "metadata.yaml")
        if not os.path.exists(meta_file):
            continue
        
        bag_paths.append(Path(bag_path))
    
    print(f"æ‰¾åˆ° {len(bag_paths)} ä¸ªbagç›®å½•")
    return bag_paths

def rename_topic(topic_name):
    topic_name_sanitized = topic_name.replace('/', '_')
    topic_name_sanitized = topic_name_sanitized.lstrip('_')
    return topic_name_sanitized

def main():
    parser = argparse.ArgumentParser(
        description="Decode H.265 data from multiple continuous ROS2 bags.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    parser.add_argument("--bag", required=True, help="è¦å¯¼å‡ºROS2 bag çš„æ ¹ç›®å½•ï¼Œé‡Œé¢åŒ…å«å¤šä¸ª bag å­ç›®å½•")
    parser.add_argument("--out", required=True, help="è¾“å‡ºæ ¹ç›®å½•,ç›®å½•è‹¥å­˜åœ¨å°†ä¼šåˆ é™¤")

    parser.add_argument("--hwaccel", type=str, default="none", choices=['none', 'nvidia', 'vaapi'], 
                        help="Specify hardware acceleration method.")
    args = parser.parse_args()

    threads, data_queues = {}, {}

    print(f"Starting bag file processing with hardware acceleration: {args.hwaccel}")
    # æ‰“å°å°†è¦æŒ‰é¡ºåºå¤„ç†çš„æ‰€æœ‰bagæ–‡ä»¶
    print(f"Input bags (will be processed in this order): {args.bag}")

    out_dir = os.path.abspath(args.out)
    input_bag_dir = os.path.abspath(args.bag)
    if input_bag_dir == out_dir:
        print(f"Error: Output directory '{out_dir}' cannot be the same as input bag directory '{input_bag_dir}'.", file=sys.stderr)
        sys.exit(1)

    # å¦‚æœè¾“å‡ºç›®å½•å­˜åœ¨ï¼Œåˆ™å…ˆåˆ é™¤
    for topic in ALL_CAMERA_H265_TOPICS:
        topic_name_sanitized = rename_topic(topic)
        topic_output_dir = os.path.join(out_dir, topic_name_sanitized)
        if os.path.exists(topic_output_dir):
            print(f"Output directory for topic '{topic}' exists at '{topic_output_dir}'. Deleting...")
            import shutil
            shutil.rmtree(topic_output_dir)
            os.makedirs(topic_output_dir, exist_ok=True)

    bag_paths = get_all_bags(args.bag)

    try:
        with AnyReader(bag_paths) as reader:
            
            # è¿™ä¸ªå¾ªç¯ç°åœ¨ä¼šæ— ç¼åœ°éå†æ‰€æœ‰bagæ–‡ä»¶ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
            for connection, timestamp, rawdata in reader.messages():
                if connection.msgtype != 'sensor_msgs/msg/Image': continue
                topic_name = connection.topic
                if topic_name not in ALL_CAMERA_H265_TOPICS:
                    print(f"\nSkipping topic: {topic_name}")
                    continue
                
                # çº¿ç¨‹å’Œç®¡çº¿åªåœ¨ç¬¬ä¸€æ¬¡é‡åˆ°topicæ—¶åˆ›å»º
                if topic_name not in threads:
                    print(f"\nDiscovered new topic: {topic_name}. Starting worker thread.")
                    q = queue.Queue(maxsize=1000)
                    data_queues[topic_name] = q
                    # è¿™ä¸ªçº¿ç¨‹å°†å­˜æ´»ï¼Œç›´åˆ°æ‰€æœ‰bagæ–‡ä»¶éƒ½è¢«å¤„ç†å®Œæ¯•
                    thread = threading.Thread(target=decode_worker, args=(topic_name, q, args.out, args.hwaccel))
                    threads[topic_name] = thread
                    thread.start()

                msg = reader.deserialize(rawdata, connection.msgtype)  # ä¿®å¤DeprecationWarning
                # æŒç»­æ¨é€æ•°æ®ï¼Œæ— éœ€å…³å¿ƒå®ƒæ¥è‡ªå“ªä¸ªbagæ–‡ä»¶
                data_queues[topic_name].put((timestamp, msg.data.tobytes()))

    except Exception as e:
        print(f"\nAn error occurred: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
    finally:
        # è¿™ä¸ª 'finally' å—åªåœ¨æ‰€æœ‰bagæ–‡ä»¶éƒ½è¢«å¤„ç†å®Œæ¯•åæ‰ä¼šæ‰§è¡Œ
        print("\nEnd of all bag files reached. Signaling worker threads to finalize...")
        for q in data_queues.values(): q.put(None)
        for t in threads.values(): t.join()
        print(f"\nAll decoding threads have finished. Program terminated. Output is in '{args.out}'")

if __name__ == '__main__':
    main()