#!/usr/bin/env python3

import os
import json
import argparse
import numpy as np
from pyproj import Proj
from scipy.spatial.transform import Rotation as R
# æ–°å¢çš„å¯¼å…¥ï¼šç”¨äºå¤„ç†æ—¶é—´æˆ³
from datetime import datetime
from typing import Dict, Any, List

# ROS 2 åº“ (éœ€è¦åœ¨ ROS 2 ç¯å¢ƒä¸­è¿è¡Œ)
try:
    from rclpy.serialization import deserialize_message
    from rosidl_runtime_py.utilities import get_message
    
    # ä¿®æ­£å¯¼å…¥ï¼šåªå¯¼å…¥æœ€åŸºç¡€çš„ç±»
    from rosbag2_py import SequentialReader, StorageOptions, ConverterOptions
    import rclpy
    
except ImportError as e:
    print(f"è‡´å‘½é”™è¯¯: æ— æ³•å¯¼å…¥ ROS 2 ç›¸å…³çš„åº“ã€‚è¯·ç¡®ä¿æ‚¨å·²æ¿€æ´» ROS 2 ç¯å¢ƒ (source /opt/ros/humble/setup.bash) ä¸” rosbag2_py å·²å®‰è£…ã€‚é”™è¯¯: {e}")
    exit(1)


# --- å¸¸é‡ ---
TARGET_MSG_TYPE = "imu_msgs/msg/Imu" 


# --- è¾…åŠ©å‡½æ•°ï¼šæ—¶é—´æˆ³è½¬æ¢ (æ–°å¢) ---

def timestamp_to_desc(timestamp_nanosec: int) -> str:
    """å°†çº³ç§’çº§æ—¶é—´æˆ³è½¬æ¢ä¸º YYYYMMDD_HHMMSS_mmm æ ¼å¼çš„æè¿°å­—ç¬¦ä¸²ã€‚"""
    # å°†çº³ç§’è½¬æ¢ä¸ºç§’
    timestamp_sec = timestamp_nanosec / 1e9
    
    # æå–æ•´æ•°ç§’å’Œæ¯«ç§’éƒ¨åˆ†
    sec = int(timestamp_sec)
    msec = int((timestamp_sec - sec) * 1000)

    # ä½¿ç”¨ç³»ç»Ÿæœ¬åœ°æ—¶é—´è¿›è¡Œè½¬æ¢ï¼ˆç¬¦åˆä¸€èˆ¬æ•°æ®è§£æä¹ æƒ¯ï¼‰
    dt_object = datetime.fromtimestamp(timestamp_sec) 
    
    # æ ¼å¼åŒ– YYYYMMDD_HHMMSS_mmm
    return dt_object.strftime("%Y%m%d_%H%M%S") + f"_{msec:03d}"


# --- è¾…åŠ©å‡½æ•°ï¼šUTM å’Œå››å…ƒæ•°è½¬æ¢ (ä¿æŒä¸å˜) ---

def get_utm_proj(latitude: float, longitude: float) -> Proj:
    """æ ¹æ®WGS84ç»çº¬åº¦åˆ›å»º pyproj.Proj å¯¹è±¡è¿›è¡Œ UTM è½¬æ¢ã€‚"""
    zone_number = int((longitude + 180) / 6) + 1
    return Proj(
        proj='utm', 
        zone=zone_number, 
        ellps='WGS84', 
        south=latitude < 0
    )

def convert_latlonalt_to_utm(latitude: float, longitude: float, altitude: float) -> Dict[str, Any]:
    """å°†WGS84ç»çº¬é«˜è½¬æ¢ä¸ºUTMåæ ‡ã€‚"""
    try:
        utm_proj = get_utm_proj(latitude, longitude)
        easting, northing = utm_proj(longitude, latitude)
        zone_number = int((longitude + 180) / 6) + 1
        
        return {
            "utm_x": easting,
            "utm_y": northing,
            "utm_z": altitude, 
            "utm_zone": zone_number
        }
    except Exception:
        return {"utm_x": None, "utm_y": None, "utm_z": None, "utm_zone": None}


def convert_rpy_to_quaternion(roll: float, pitch: float, azimuth: float) -> Dict[str, float]:
    """å°†æ¬§æ‹‰è§’ (Roll, Pitch, Azimuth/Yaw) è½¬æ¢ä¸ºå››å…ƒæ•°ã€‚"""
    roll_rad = roll
    pitch_rad = pitch
    yaw_rad = azimuth 
    
    try:
        # ä½¿ç”¨ ZYX é¡ºåº (Yaw-Pitch-Roll)
        r = R.from_euler('zyx', [yaw_rad, pitch_rad, roll_rad])
        quaternion = r.as_quat() # è¿”å› (x, y, z, w) æ ¼å¼
        
        return {
            "quaternion_x": quaternion[0],
            "quaternion_y": quaternion[1],
            "quaternion_z": quaternion[2],
            "quaternion_w": quaternion[3],
        }
    except Exception:
        return {"quaternion_x": None, "quaternion_y": None, "quaternion_z": None, "quaternion_w": None}


# --- ROS 2 Bag è§£æé€»è¾‘ ---

def process_single_bag(bag_path: str) -> List[Dict[str, Any]]:
    """
    å¤„ç†å•ä¸ª ROS 2 bag æ–‡ä»¶ï¼Œè¯»å–æ‰€æœ‰æ¶ˆæ¯ï¼Œå¹¶æ‰‹åŠ¨è¿‡æ»¤ç›®æ ‡è¯é¢˜ã€‚
    """
    extracted_data: List[Dict[str, Any]] = []
    
    # ç”¨äºå­˜å‚¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆå¸§çš„ UTM åæ ‡ (æ–°å¢)
    first_utm: Dict[str, float] = {}

    # 1. è®¾ç½® Reader
    storage_options = StorageOptions(uri=bag_path, storage_id='sqlite3') 
    converter_options = ConverterOptions(
        input_serialization_format='cdr',
        output_serialization_format='cdr'
    )
    
    reader = SequentialReader()
    try:
        reader.open(storage_options, converter_options)
        
        # 2. è‡ªåŠ¨æ£€æµ‹è¯é¢˜
        topics_and_types = reader.get_all_topics_and_types()
        
        target_topic_info = None
        topic_map = {}
        
        for topic_info in topics_and_types:
            try:
                # æ¶ˆæ¯ç±»å‹å¯¹è±¡
                msg_type_obj = get_message(topic_info.type)
                topic_map[topic_info.name] = (topic_info.type, msg_type_obj)
                
                # æ‰¾åˆ°ç›®æ ‡è¯é¢˜çš„ä¿¡æ¯
                if topic_info.type == TARGET_MSG_TYPE:
                    target_topic_info = topic_info 
            except ImportError:
                # å¿½ç•¥æ— æ³•å¯¼å…¥çš„æ¶ˆæ¯ç±»å‹
                continue
        
        if not target_topic_info:
            print(f"âŒ è­¦å‘Š: Bag '{bag_path}' ä¸­æœªæ‰¾åˆ°ç±»å‹ä¸º '{TARGET_MSG_TYPE}' çš„è¯é¢˜ã€‚")
            return extracted_data
            
        print(f"âœ… æ‰¾åˆ°ç›®æ ‡è¯é¢˜: {target_topic_info.name}, ç±»å‹: {target_topic_info.type}")
        
        # è·å–ç›®æ ‡æ¶ˆæ¯å¯¹è±¡
        _, msg_type_obj = topic_map[target_topic_info.name]


        # 3. å¾ªç¯è¯»å–æ¶ˆæ¯ (ä¸è®¾ç½®è¿‡æ»¤å™¨ï¼Œå…¼å®¹æ€§æœ€å¥½)
        while reader.has_next():
            topic_name, data, timestamp = reader.read_next()
            
            # 4. æ‰‹åŠ¨è¿‡æ»¤éç›®æ ‡è¯é¢˜çš„æ¶ˆæ¯
            if topic_name != target_topic_info.name:
                continue

            try:
                # ååºåˆ—åŒ– Imu æ¶ˆæ¯
                imu_msg = deserialize_message(data, msg_type_obj)
                
                # æå– ASENSING å­æ¶ˆæ¯çš„å­—æ®µ 
                # å‡è®¾ 'imu_msgs/msg/Imu' æ¶ˆæ¯åŒ…å«ä¸€ä¸ªåä¸º 'imu_msg' çš„å­å­—æ®µ
                ins_data = imu_msg.imu_msg 
                
                # æå–æ•°æ®
                latitude = ins_data.latitude
                longitude = ins_data.longitude
                altitude = ins_data.altitude
                roll = ins_data.roll
                pitch = ins_data.pitch
                azimuth = ins_data.azimuth

                # 5. æ‰§è¡Œè½¬æ¢
                utm_coords = convert_latlonalt_to_utm(latitude, longitude, altitude)
                quaternions = convert_rpy_to_quaternion(roll, pitch, azimuth)

                # --- æ–°å¢é€»è¾‘ï¼šè®¡ç®—ç›¸å¯¹ UTM åæ ‡ ---
                if not first_utm and utm_coords['utm_x'] is not None:
                    # è®°å½•ç¬¬ä¸€ä¸ªæœ‰æ•ˆå¸§çš„ UTM åæ ‡ä½œä¸ºåŸç‚¹
                    first_utm = {
                        'utm_x': utm_coords['utm_x'],
                        'utm_y': utm_coords['utm_y'],
                        'utm_z': utm_coords['utm_z'],
                    }
                
                # è®¡ç®—ç›¸å¯¹åæ ‡
                if first_utm:
                    tran_utm_x = utm_coords['utm_x'] - first_utm['utm_x']
                    tran_utm_y = utm_coords['utm_y'] - first_utm['utm_y']
                    tran_utm_z = utm_coords['utm_z'] - first_utm['utm_z']
                else:
                    # å¦‚æœç¬¬ä¸€ä¸ªæœ‰æ•ˆå¸§çš„åæ ‡æ— æ•ˆï¼Œåˆ™æ— æ³•è®¡ç®—ç›¸å¯¹åæ ‡
                    tran_utm_x, tran_utm_y, tran_utm_z = None, None, None

                # --- æ–°å¢é€»è¾‘ï¼šæ—¶é—´æˆ³æè¿° ---
                timestamp_desc = timestamp_to_desc(timestamp)


                # 6. å­˜å‚¨ç»“æœ (åŒ…å«æ‰€æœ‰æ–°å¢å­—æ®µ)
                result = {
                    "timestamp_nanosec": timestamp,
                    "timestamp_desc": timestamp_desc, # æ–°å¢å­—æ®µ 1
                    "latitude": latitude,
                    "longitude": longitude,
                    "altitude": altitude,
                    "roll": roll,
                    "pitch": pitch,
                    "azimuth": azimuth,
                    "tran_utm_x": tran_utm_x, # æ–°å¢å­—æ®µ 2
                    "tran_utm_y": tran_utm_y, # æ–°å¢å­—æ®µ 3
                    "tran_utm_z": tran_utm_z, # æ–°å¢å­—æ®µ 4
                }
                result.update(utm_coords) # åŒ…å« utm_x, utm_y, utm_z
                result.update(quaternions)
                
                extracted_data.append(result)

            except Exception as e:
                # æ‰“å°å…·ä½“çš„è¯é¢˜åå’Œé”™è¯¯ï¼Œä¾¿äºè°ƒè¯•
                print(f"âŒ è­¦å‘Š: Bag '{bag_path}' (Topic: {target_topic_info.name}) ä¸­ä¸€æ¡æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
                continue

    except Exception as e:
        # åœ¨è¿™é‡Œæ•è·çš„é”™è¯¯é€šå¸¸æ˜¯æ‰“å¼€æ–‡ä»¶å¤±è´¥æˆ–åº•å±‚å­˜å‚¨æ’ä»¶çš„é”™è¯¯
        print(f"âŒ é”™è¯¯: æ— æ³•æ‰“å¼€æˆ–è¯»å– Bag æ–‡ä»¶ '{bag_path}': {e}")
        
    finally:
        # é¿å… AttributeError å´©æºƒ
        pass
        
    return extracted_data


def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°ï¼Œéå†ç›®å½•å¹¶è°ƒç”¨å¤„ç†å‡½æ•°ã€‚
    """
    try:
        import rclpy
    except ImportError:
        print("è‡´å‘½é”™è¯¯: æ— æ³•å¯¼å…¥ rclpyã€‚è¯·ç¡®ä¿ ROS 2 ç¯å¢ƒå·²æ¿€æ´»ã€‚")
        return
        
    rclpy.init(args=None) # åˆå§‹åŒ– rclpy

    parser = argparse.ArgumentParser(
        description=f"è§£æ ROS 2 bag æ–‡ä»¶ä¸­çš„ç±»å‹ä¸º '{TARGET_MSG_TYPE}' çš„ INS æ¶ˆæ¯ï¼Œè½¬æ¢ä¸º UTM åæ ‡å’Œå››å…ƒæ•°ï¼Œå¹¶è¾“å‡º JSON æ–‡ä»¶ã€‚"
    )
    parser.add_argument(
        "--bag",
        type=str,
        dest="input_dir",
        required=True,
        help="åŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ª ROS 2 bag æ–‡ä»¶å¤¹çš„çˆ¶è·¯å¾„ã€‚"
    )
    parser.add_argument(
        "--out",
        type=str,
        dest="output_file", 
        required=True,
        help="æ‰€æœ‰è½¬æ¢æ•°æ®å°†å­˜å‚¨åˆ°çš„æœ€ç»ˆ JSON æ–‡ä»¶è·¯å¾„ã€‚"
    )

    args = parser.parse_args()

    
    input_dir = args.input_dir
    output_file = args.output_file

    all_data = []
    
    # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_dir):
        print(f"âŒ é”™è¯¯ï¼šè¾“å…¥è·¯å¾„ä¸å­˜åœ¨ï¼š{input_dir}")
        return
    
    # åˆ¤æ–­è¾“å…¥è·¯å¾„æœ¬èº«æ˜¯å¦æ˜¯ä¸€ä¸ªbagç›®å½•ï¼ˆåŒ…å«metadata.yamlï¼‰
    meta_file = os.path.join(input_dir, "metadata.yaml")
    if os.path.exists(meta_file):
        # å•ç›®å½•æ¨¡å¼ï¼šç›´æ¥å¤„ç†è¿™ä¸ªç›®å½•
        print(f"âœ… è¾“å…¥è·¯å¾„æ˜¯å•ä¸ªbagç›®å½•ï¼š{input_dir}")
        bag_paths = [input_dir]
    else:
        # å¤šç›®å½•æ¨¡å¼ï¼šéå†å­ç›®å½•
        print(f"ğŸ“ æŒ‰å¤šç›®å½•æ¨¡å¼å¤„ç†ï¼šéå† {input_dir} çš„å­ç›®å½•")
        bag_paths = []
        
        try:
            entries = os.listdir(input_dir)
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–ç›®å½• {input_dir}: {e}")
            return
        
        if not entries:
            print(f"âš ï¸  ç›®å½•ä¸ºç©ºï¼š{input_dir}")
            return
        
        # éå†å­ç›®å½•ï¼ŒæŸ¥æ‰¾bagç›®å½•
        bag_count = 0
        for entry in sorted(entries):
            bag_path = os.path.join(input_dir, entry)
            
            # åªå¤„ç†ç›®å½•
            if not os.path.isdir(bag_path):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„bagç›®å½•
            meta_file = os.path.join(bag_path, "metadata.yaml")
            if not os.path.exists(meta_file):
                # ä¸æ˜¯bagç›®å½•ï¼Œè·³è¿‡
                continue
            
            bag_paths.append(bag_path)
            bag_count += 1
            print(f"  æ‰¾åˆ°bagç›®å½• {bag_count}: {entry}")
        
        if bag_count == 0:
            print(f"âš ï¸  è­¦å‘Šï¼šåœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„bagç›®å½•")
            print(f"   æ£€æŸ¥ç›®å½•ç»“æ„ï¼šåº”æœ‰å­ç›®å½•ï¼Œæ¯ä¸ªå­ç›®å½•åŒ…å« metadata.yaml")
            return

    print(f"æ€»è®¡æ‰¾åˆ° {len(bag_paths)} ä¸ªbagç›®å½•")
    
    # å¤„ç†æ¯ä¸ªbagç›®å½•
    for bag_path in bag_paths:
        print(f"\nğŸš€ æ­£åœ¨å¤„ç† Bag: {bag_path}")
        data = process_single_bag(bag_path)
        if data:
            print(f"âœ… å®Œæˆå¤„ç†ã€‚æå–äº† {len(data)} æ¡æ¶ˆæ¯ã€‚")
            all_data.extend(data)
        else:
            print(f"ğŸ›‘ Bag '{bag_path}' å¤„ç†å®Œæˆï¼Œä½†æœªæå–åˆ°æœ‰æ•ˆæ•°æ®ã€‚")

    # å†™å…¥æœ€ç»ˆçš„ JSON æ–‡ä»¶
    if all_data:
        print(f"\nğŸ‰ æ‰€æœ‰ Bag å¤„ç†å®Œæ¯•ã€‚æ€»å…±æå–äº† {len(all_data)} æ¡æ•°æ®ã€‚")
        try:
            # è‡ªå®šä¹‰ç¼–ç å™¨å¤„ç† numpy ç±»å‹
            class CustomJSONEncoder(json.JSONEncoder):
                def default(self, obj):
                    if isinstance(obj, np.integer):
                        return int(obj)
                    elif isinstance(obj, np.floating):
                        return float(obj)
                    return json.JSONEncoder.default(self, obj)

            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(all_data, f, ensure_ascii=False, indent=4, cls=CustomJSONEncoder)
            print(f"ğŸ’¾ æ•°æ®å·²æˆåŠŸå†™å…¥åˆ° JSON æ–‡ä»¶: {output_file}")
        except IOError as e:
            print(f"âŒ é”™è¯¯: æ— æ³•å†™å…¥è¾“å‡ºæ–‡ä»¶ '{output_file}': {e}")
    else:
        print("\nâš ï¸ è­¦å‘Š: æœªä»ä»»ä½• Bag æ–‡ä»¶ä¸­æå–åˆ°æ•°æ®ï¼Œæœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶ã€‚")
        
    rclpy.shutdown()

if __name__ == "__main__":
    main()