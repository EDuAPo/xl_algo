#!/usr/bin/env python3

from datetime import datetime
import os
import argparse
import numpy as np
from tqdm import tqdm
import rosbag2_py
from sensor_msgs.msg import PointCloud2, PointField
from sensor_msgs_py import point_cloud2 
import struct
from tqdm import tqdm
import shutil
import threading
import queue

# --- å…¼å®¹ä¸åŒ ROS2 ç‰ˆæœ¬çš„ååºåˆ—åŒ–æ¥å£ ---
try:
    from rosidl_runtime_py.utilities import get_message, deserialize_message
except ImportError:
    # æŸäº›è€ç‰ˆæœ¬å¯èƒ½éœ€è¦è¿™æ ·å¯¼å…¥
    from rosidl_runtime_py.utilities import get_message
    from rclpy.serialization import deserialize_message

# çº¿ç¨‹é€šä¿¡ç”¨çš„ Stop æ ‡å¿—
STOP_SIGNAL = "STOP"

# ROS PointField æ•°æ®ç±»å‹åˆ° NumPy dtype çš„æ˜ å°„
TYPE_MAP = {
    PointField.INT8: np.dtype('int8'),
    PointField.UINT8: np.dtype('uint8'),
    PointField.INT16: np.dtype('int16'),
    PointField.UINT16: np.dtype('uint16'),
    PointField.INT32: np.dtype('int32'),
    PointField.UINT32: np.dtype('uint32'),
    PointField.FLOAT32: np.dtype('float32'),
    PointField.FLOAT64: np.dtype('float64'),
}

# --- ã€æœ€ç»ˆä¼˜åŒ–ã€‘ç›´æ¥ä»æ¶ˆæ¯å­—èŠ‚ç¼“å†²åŒºè¯»å–ç‚¹äº‘æ•°æ® ---
def read_points_from_buffer(msg: PointCloud2) -> np.ndarray:
    """
    é€šè¿‡ np.frombuffer ç›´æ¥è¯»å– PointCloud2 çš„åŸå§‹å­—èŠ‚æ•°æ®ï¼Œ
    ç»•è¿‡ sensor_msgs_py çš„ä½æ•ˆ Python å¾ªç¯ã€‚
    """
    if not msg.fields:
        return np.empty((0,))

    # 1. åŠ¨æ€æ„å»º NumPy ç»“æ„åŒ–æ•°ç»„çš„ dtype
    dtype_list = []
    current_offset = 0
    
    for field in msg.fields:
        # 1.1 å¤„ç†å­—èŠ‚å¯¹é½/Padding
        if field.offset > current_offset:
            padding_size = field.offset - current_offset
            # æ’å…¥ padding å­—æ®µ
            dtype_list.append((f'_pad_{current_offset}', np.dtype('uint8'), padding_size))
            current_offset += padding_size
            
        # 1.2 è·å– NumPy ç±»å‹
        np_type = TYPE_MAP.get(field.datatype)
        if np_type is None:
             raise ValueError(f"Unsupported PointField datatype: {field.datatype}")
             
        # 1.3 æ·»åŠ å­—æ®µ
        # PointField.count å…è®¸ä¸€ä¸ªå­—æ®µæœ‰å¤šä¸ªå…ƒç´ ï¼Œä½†é€šå¸¸ LiDAR ä¸º 1
        if field.count > 1:
             dtype_list.append((field.name, np_type, field.count))
        else:
             dtype_list.append((field.name, np_type))
        
        current_offset += np_type.itemsize * field.count

    # 2. ç¡®ä¿ PointStep çš„å®Œæ•´æ€§ï¼ˆå¯èƒ½å­˜åœ¨å°¾éƒ¨ paddingï¼‰
    if msg.point_step > current_offset:
        padding_size = msg.point_step - current_offset
        print(f"âš ï¸ æ³¨æ„: åœ¨å­—æ®µæœ«å°¾æ·»åŠ  padding å¤§å° {padding_size} å­—èŠ‚ä»¥åŒ¹é… point_step {msg.point_step}")
        dtype_list.append((f'_pad_end', np.dtype('uint8'), padding_size))

    # 3. åˆ›å»ºæœ€ç»ˆ dtype
    point_dtype = np.dtype(dtype_list)

    # 4. ä½¿ç”¨ np.frombuffer åˆ›å»ºç»“æ„åŒ–æ•°ç»„è§†å›¾
    num_points = int(len(msg.data) / msg.point_step)
    cloud_arr = np.frombuffer(
        msg.data, 
        dtype=point_dtype, 
        count=num_points
    )
    
    # 5. å¤„ç†å­—èŠ‚åº (Endianness)
    if msg.is_bigendian:
        # å¦‚æœæ˜¯å¤§ç«¯åºï¼Œéœ€è¦å­—èŠ‚äº¤æ¢
        cloud_arr = cloud_arr.byteswap().newbyteorder('<')

    return cloud_arr

# --- è¾…åŠ©å‡½æ•°ï¼šPCD Header ç”Ÿæˆ ---
def generate_pcd_header(num_points, fields, data_type):
    """ç”Ÿæˆ PCD æ–‡ä»¶å¤´ (ASCII æˆ– BINARY)"""
    # è¿™é‡Œçš„ fields åº”è¯¥æ˜¯ ['x', 'y', 'z', ...] (ä¸å« padding)
    header = [
        "# .PCD v0.7 - Point Cloud Data file format",
        "VERSION 0.7",
        f"FIELDS {' '.join(fields)}",
        # å‡è®¾æ‰€æœ‰å¯¼å‡ºçš„å­—æ®µéƒ½æ˜¯ float32 (4å­—èŠ‚)
        f"SIZE {' '.join(['4' for _ in fields])}",
        f"TYPE {' '.join(['F' for _ in fields])}",
        f"COUNT {' '.join(['1' for _ in fields])}",
        f"WIDTH {num_points}",
        "HEIGHT 1",
        "VIEWPOINT 0 0 0 1 0 0 0",
        f"POINTS {num_points}",
        f"DATA {data_type}"
    ]
    return '\n'.join(header) + '\n'

# --- è¾…åŠ©å‡½æ•°ï¼šå°†ç»“æ„åŒ–æ•°ç»„è½¬æ¢ä¸ºè¿ç»­ float32 æ•°ç»„ ---
def struct_to_contiguous_float32(points, fields):
    """
    å°†ç»“æ„åŒ–æ•°ç»„ï¼ˆåŒ…å« paddingï¼‰è½¬æ¢ä¸ºè¿ç»­çš„ (N, F) float32 æ•°ç»„ã€‚
    fields å‚æ•°å¿…é¡»æ˜¯éœ€è¦ä¿å­˜çš„å­—æ®µåˆ—è¡¨ (ä¸å« padding)ã€‚
    """
    # è¿™é‡Œçš„ fields å·²ç»æ˜¯éœ€è¦ä¿å­˜çš„å­—æ®µåˆ—è¡¨ (e.g., ['x', 'y', 'z', 'intensity'])
    valid_fields = fields 
    num_points = len(points)
    num_fields = len(valid_fields)
    
    if num_points == 0:
        return np.empty((0, num_fields), dtype=np.float32)

    # é¢„åˆ†é…ç›®æ ‡æ•°ç»„
    points_float32 = np.empty((num_points, num_fields), dtype=np.float32)

    # é€åˆ—èµ‹å€¼ï¼Œä»ç»“æ„åŒ–æ•°ç»„æå–æ•°æ®å¹¶è½¬æ¢ç±»å‹
    for i, field_name in enumerate(valid_fields):
        # æå–å­—æ®µæ•°æ®å¹¶è½¬æ¢ä¸º float32 èµ‹å€¼åˆ°æ–°æ•°ç»„çš„åˆ—
        points_float32[:, i] = points[field_name].astype(np.float32) 
        
    return points_float32

# --- è¾…åŠ©å‡½æ•°ï¼šä¿å­˜ PCD (ASCII) ---
def save_pcd_ascii(filename, points, fields):
    """ä»¥ ASCII æ–¹å¼ä¿å­˜ .pcd æ–‡ä»¶ (points æ˜¯ç»“æ„åŒ–æ•°ç»„)"""
    num_points = len(points)
    header = generate_pcd_header(num_points, fields, "ascii")
    
    # ASCII æ ¼å¼å¿…é¡»ä½¿ç”¨ np.savetxt
    points_2d = np.column_stack([points[name] for name in fields])
    
    with open(filename, 'w') as f:
        f.write(header)
        np.savetxt(f, points_2d, fmt="%.6f")

# --- è¾…åŠ©å‡½æ•°ï¼šä¿å­˜ PCD (BINARY) ---
def save_pcd_binary(filename, points, fields):
    """ä»¥ BINARY æ–¹å¼ä¿å­˜ .pcd æ–‡ä»¶ (points æ˜¯ç»“æ„åŒ–æ•°ç»„)"""
    num_points = len(points)
    if num_points == 0:
        return

    # 1. ç”Ÿæˆæ–‡ä»¶å¤´
    header = generate_pcd_header(num_points, fields, "binary")

    # 2. ã€ä¼˜åŒ–ã€‘è½¬æ¢ä¸ºè¿ç»­ float32 æ•°ç»„
    points_float32 = struct_to_contiguous_float32(points, fields)
        
    # 3. å†™å…¥æ–‡ä»¶
    with open(filename, 'wb') as f:
        f.write(header.encode('ascii'))
        f.write(points_float32.tobytes()) # å†™å…¥è¿ç»­çš„å­—èŠ‚æ•°æ®


# --- è¾…åŠ©å‡½æ•°ï¼šä¿å­˜ BIN ---
def save_bin(filename, points, fields):
    """ä»¥äºŒè¿›åˆ¶æ–¹å¼ä¿å­˜ .bin æ–‡ä»¶ (points æ˜¯ç»“æ„åŒ–æ•°ç»„)"""
    if not fields or len(points) == 0:
        return
        
    # 1. ã€ä¼˜åŒ–ã€‘è½¬æ¢ä¸ºè¿ç»­ float32 æ•°ç»„
    points_float32 = struct_to_contiguous_float32(points, fields)

    # 2. å°† NumPy æ•°ç»„ç›´æ¥å†™å…¥æ–‡ä»¶
    points_float32.tofile(filename)


# --- è¾…åŠ©å‡½æ•°ï¼šç»Ÿä¸€ä¿å­˜æ¥å£ ---
def save_points(filename_base, points, fields, export_format):
    """æ ¹æ®æŒ‡å®šçš„æ ¼å¼è°ƒç”¨ä¸åŒçš„ä¿å­˜å‡½æ•°"""
    if export_format == 'pcd_ascii':
        filename = f"{filename_base}.pcd"
        save_pcd_ascii(filename, points, fields)
    elif export_format == 'pcd_binary':
        filename = f"{filename_base}.pcd"
        save_pcd_binary(filename, points, fields)
    elif export_format == 'bin':
        filename = f"{filename_base}.bin"
        save_bin(filename, points, fields)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}")


# --- è¾…åŠ©å‡½æ•°ï¼šæŸ¥æ‰¾ PointCloud2 Topics (ä¿æŒä¸å˜) ---
def list_pointcloud2_topics(bag_path):
    reader = rosbag2_py.SequentialReader()
    storage_options = rosbag2_py.StorageOptions(uri=bag_path, storage_id="sqlite3")
    converter_options = rosbag2_py.ConverterOptions("", "")
    reader.open(storage_options, converter_options)
    metadata = reader.get_metadata()
    topics = []
    topic_types = {}
    for t in metadata.topics_with_message_count:
        if "PointCloud2" in t.topic_metadata.type:
            topics.append(t.topic_metadata.name)
            topic_types[t.topic_metadata.name] = t.topic_metadata.type
            print(f"Topic: {t.topic_metadata.name}, type: {t.topic_metadata.type}, count: {t.message_count}")
    return topics, topic_types, metadata.topics_with_message_count

# --- å·¥ä½œçº¿ç¨‹ï¼šå¤„ç†å•ä¸ª Topic çš„æ¶ˆæ¯å¹¶ä¿å­˜ ---
class TopicExporter(threading.Thread):
    def __init__(self, topic_name, msg_type, msg_queue, out_dir, total_msgs, export_format):
        super().__init__()
        self.topic_name = topic_name
        self.msg_type = msg_type
        self.msg_queue = msg_queue
        self.out_dir = out_dir
        self.total_msgs = total_msgs
        self.export_format = export_format # æ ¼å¼å‚æ•°
        self.msg_count = 0
        self.fields_printed = False
        
        # æ€§èƒ½ç›‘æ§
        self.start_time = datetime.now()
        self.last_check_time = datetime.now()
        self.last_check_count = 0
        self.time_stats = {'deserialize': [], 'read_points': [], 'format': [], 'save': []}
        
        # æ ¹æ®æ ¼å¼å‚æ•°è®¾ç½®å­ç›®å½•å (pcd_ascii, pcd_binary, bin)
        format_dir = export_format.lower() 
        self.pcd_dir = os.path.join(out_dir, topic_name.strip("/").replace("/", "_"), format_dir)
        os.makedirs(self.pcd_dir, exist_ok=True)
        self.pbar = tqdm(total=total_msgs, desc=f"Saving {topic_name} to {export_format.upper()}", ncols=100)

    def run(self):
        while True:
            item = self.msg_queue.get()
            if item == STOP_SIGNAL:
                self.msg_queue.task_done()
                break

            # item æ˜¯ (data, timestamp)
            data, t = item
            self.process_message(data, t)
            self.msg_queue.task_done()
            self.pbar.update(1)

        self.pbar.close()
        
        # è®¡ç®—æœ€ç»ˆç»Ÿè®¡
        total_time = (datetime.now() - self.start_time).total_seconds()
        avg_fps = self.msg_count / total_time if total_time > 0 else 0
        
        avg_stats = {k: sum(v)/len(v) if v else 0 for k, v in self.time_stats.items()}
        
        print(f"\n{'='*80}")
        print(f"ğŸ‰ Topic {self.topic_name} å¯¼å‡ºå®Œæˆ")
        print(f"{'='*80}")
        print(f"  æ€»å¸§æ•°: {self.msg_count}")
        print(f"  ä¿å­˜è‡³: {self.pcd_dir}")
        print(f"  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"  å¹³å‡é€Ÿç‡: {avg_fps:.2f} fps")
        print(f"  å„é˜¶æ®µå¹³å‡è€—æ—¶:")
        print(f"    - ååºåˆ—åŒ–: {avg_stats['deserialize']:.2f}ms")
        print(f"    - è¯»å–ç‚¹äº‘: {avg_stats['read_points']:.2f}ms")
        print(f"    - æ ¼å¼åŒ–: {avg_stats['format']:.2f}ms")
        print(f"    - ä¿å­˜æ–‡ä»¶: {avg_stats['save']:.2f}ms")
        print(f"  æ¯å¸§å¹³å‡æ€»è€—æ—¶: {sum(avg_stats.values()):.2f}ms")
        print(f"{'='*80}")

    def process_message(self, data, t):
        start_time_total = datetime.now() # å¼€å§‹æ€»è®¡æ—¶

        # 1. ååºåˆ—åŒ–
        start_time = datetime.now()
        msg = deserialize_message(data, self.msg_type)
        time_deserialize = (datetime.now() - start_time).total_seconds() * 1000 # ms

        # 2. ã€æœ€ç»ˆä¼˜åŒ–ã€‘ä½¿ç”¨è‡ªå®šä¹‰çš„ np.frombuffer é€»è¾‘
        start_time = datetime.now()
        cloud_arr = read_points_from_buffer(msg) 
        time_read_points = (datetime.now() - start_time).total_seconds() * 1000 # ms

        # 3. æ•°æ®å¤„ç†
        start_time = datetime.now()
        # FIX: æ­£ç¡®æå–éœ€è¦ä¿å­˜çš„å­—æ®µååˆ—è¡¨
        field_names_to_save = [f.name for f in msg.fields]
        
        # cloud_arr å·²ç»æ˜¯åŒ…å« padding çš„ç»“æ„åŒ–æ•°ç»„ï¼Œç›´æ¥ä¼ é€’
        points_to_save = cloud_arr 
        time_format_data = (datetime.now() - start_time).total_seconds() * 1000 # ms

        # 4. æ–‡ä»¶ä¿å­˜ (I/O)
        timestamp_sec = t / 1e9
        dt = datetime.fromtimestamp(timestamp_sec)
        timestamp_str = dt.strftime("%Y%m%d_%H%M%S_%f")[:-3]  # ç²¾ç¡®åˆ°æ¯«ç§’
        file_base = os.path.join(self.pcd_dir, f"{timestamp_str}") 

        start_time = datetime.now()
        # è°ƒç”¨ç»Ÿä¸€ä¿å­˜æ¥å£ï¼Œä¼ å…¥æ­£ç¡®æå–çš„å­—æ®µååˆ—è¡¨
        save_points(file_base, points_to_save, field_names_to_save, self.export_format) 
        time_save_file = (datetime.now() - start_time).total_seconds() * 1000 # ms
        
        # 5. æ”¶é›†æ€§èƒ½æ•°æ®
        self.msg_count += 1
        self.time_stats['deserialize'].append(time_deserialize)
        self.time_stats['read_points'].append(time_read_points)
        self.time_stats['format'].append(time_format_data)
        self.time_stats['save'].append(time_save_file)
        
        # 6. æ€§èƒ½ç›‘æ§å’Œå˜æ…¢æ£€æµ‹
        if self.msg_count % 200 == 0:  # æ¯200å¸§æ£€æŸ¥ä¸€æ¬¡
            current_time = datetime.now()
            elapsed = (current_time - self.start_time).total_seconds()
            interval = (current_time - self.last_check_time).total_seconds()
            frames_in_interval = self.msg_count - self.last_check_count
            
            overall_fps = self.msg_count / elapsed if elapsed > 0 else 0
            interval_fps = frames_in_interval / interval if interval > 0 else 0
            
            # è®¡ç®—æœ€è¿‘200å¸§çš„å¹³å‡è€—æ—¶
            recent_stats = {k: sum(v[-200:])/len(v[-200:]) if v[-200:] else 0 for k, v in self.time_stats.items()}
            
            time_total = (datetime.now() - start_time_total).total_seconds() * 1000
            print(f"\n{'='*80}")
            print(f"ğŸ“Š [{self.topic_name}] æ€§èƒ½æ£€æµ‹ - ç¬¬ {self.msg_count} å¸§")
            print(f"{'='*80}")
            print(f"  å½“å‰å¸§ ({len(points_to_save)} pts): {time_total:.2f}ms")
            print(f"  æœ€è¿‘200å¸§å¹³å‡:")
            print(f"    - ååºåˆ—åŒ–: {recent_stats['deserialize']:.2f}ms")
            print(f"    - è¯»å–ç‚¹äº‘: {recent_stats['read_points']:.2f}ms")
            print(f"    - æ ¼å¼åŒ–: {recent_stats['format']:.2f}ms")
            print(f"    - ä¿å­˜æ–‡ä»¶: {recent_stats['save']:.2f}ms")
            print(f"    - åˆè®¡å¹³å‡: {sum(recent_stats.values()):.2f}ms")
            print(f"  å¤„ç†é€Ÿç‡:")
            print(f"    - æ€»ä½“é€Ÿç‡: {overall_fps:.2f} fps")
            print(f"    - å½“å‰åŒºé—´: {interval_fps:.2f} fps")
            print(f"  æ€»è€—æ—¶: {elapsed:.1f}s")
            
            # å˜æ…¢è­¦å‘Š
            if self.msg_count > 400 and interval_fps < overall_fps * 0.7:
                print(f"  âš ï¸  è­¦å‘Š: å¤„ç†é€Ÿåº¦ä¸‹é™ {((1 - interval_fps/overall_fps) * 100):.1f}%")
            
            print(f"{'='*80}")
            
            self.last_check_time = current_time
            self.last_check_count = self.msg_count


# --- æ ¸å¿ƒå‡½æ•°ï¼šç»Ÿä¸€è¯»å–å¹¶åˆ†å‘æ¶ˆæ¯ (ä¿æŒä¸å˜) ---
def export_one_bag(bag_path, out_dir, export_format):
    # 1. è¯†åˆ« PointCloud2 Topics
    topics, topic_types_str, topics_meta = list_pointcloud2_topics(bag_path)
    if not topics:
        print("âŒ æœªæ£€æµ‹åˆ° PointCloud2 topics")
        return

    print("\næ£€æµ‹åˆ°ä»¥ä¸‹ PointCloud2 topics:")
    for i, t in enumerate(topics):
        count = next(m.message_count for m in topics_meta if m.topic_metadata.name == t)
        print(f"  [{i}] {t} (Count: {count})")

    # 2. åˆå§‹åŒ–é˜Ÿåˆ—å’Œå·¥ä½œçº¿ç¨‹
    topic_queues = {topic: queue.Queue(maxsize=100) for topic in topics}
    exporter_threads = []
    total_messages_to_export = 0

    for topic in topics:
        topic_msg_type_str = topic_types_str[topic]
        msg_type = get_message(topic_msg_type_str)
        
        # è·å–æ¶ˆæ¯æ€»æ•°
        topic_count = next(m.message_count for m in topics_meta if m.topic_metadata.name == topic)
        total_messages_to_export += topic_count

        thread = TopicExporter(
            topic_name=topic, 
            msg_type=msg_type, 
            msg_queue=topic_queues[topic], 
            out_dir=out_dir, 
            total_msgs=topic_count,
            export_format=export_format # ä¼ é€’æ ¼å¼å‚æ•°
        )
        exporter_threads.append(thread)
        thread.start()

    # 3. é…ç½® SequentialReader å¹¶è¯»å–æ•°æ®
    storage_options = rosbag2_py.StorageOptions(uri=bag_path, storage_id="sqlite3")
    converter_options = rosbag2_py.ConverterOptions("", "")
    
    # ä½¿ç”¨ SequentialReader è¿›è¡Œä¸€æ¬¡éå†
    reader = rosbag2_py.SequentialReader()
    reader.open(storage_options, converter_options)
    
    # è®¾ç½® Topic è¿‡æ»¤å™¨ï¼Œåªè¯»å– PointCloud2 æ¶ˆæ¯
    reader.set_filter(rosbag2_py.StorageFilter(topics))

    # 4. ä¸»çº¿ç¨‹ï¼šè¯»å–å¹¶æŠ•é€’æ¶ˆæ¯
    print("\n[INFO] ä¸»çº¿ç¨‹å¼€å§‹è¯»å–æ•°æ®å¹¶åˆ†å‘...")
    
    total_messages_read = 0
    total_read_time = 0.0
    
    with tqdm(total=total_messages_to_export, desc="Reading and Dispatching", ncols=100) as pbar_read:
        while reader.has_next():
            start_time = datetime.now()
            # (topic, data, t) ä»ç„¶æ˜¯ SequenceReader çš„è¿”å›æ ¼å¼
            (topic, data, t) = reader.read_next()
            read_time = (datetime.now() - start_time).total_seconds() * 1000 # ms
            total_read_time += read_time
            total_messages_read += 1
            
            if topic in topic_queues:
                topic_queues[topic].put((data, t)) 
                pbar_read.update(1)
            
            # æ‰“å°ä¸»çº¿ç¨‹è¯»å–è€—æ—¶ (ä»…å¯¹å‰å‡ å¸§æˆ–å®šæœŸæ‰“å°)
            if total_messages_read <= 5 or total_messages_read % 500 == 0:  # ä¼˜åŒ–ï¼šé™ä½è‡³æ¯500å¸§
                 print(f"[LOG] Main Thread Read Frame {total_messages_read} | Read/Dispatch Time: {read_time:.2f}ms")

    # 5. å‘é€åœæ­¢ä¿¡å·å¹¶ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    avg_read_time = total_read_time / total_messages_read if total_messages_read > 0 else 0
    print(f"\n[INFO] ä¸»çº¿ç¨‹è¯»å–å®Œæˆï¼Œæ€»è¯»å–æ¶ˆæ¯ {total_messages_read} å¸§ã€‚å¹³å‡è¯»å–è€—æ—¶: {avg_read_time:.2f}ms")
    for topic, q in topic_queues.items():
        q.put(STOP_SIGNAL)

    for thread in exporter_threads:
        thread.join()

    print(f"\nâœ… Bag {bag_path} æ‰€æœ‰ PointCloud2 Topics å¯¼å‡ºå®Œæˆï¼")

    
# --- Main å‡½æ•° (ä¿æŒä¸å˜) ---
def main():
    parser = argparse.ArgumentParser(description="å¤šçº¿ç¨‹å¯¼å‡ºå¤šä¸ª ROS2 bag çš„ Lidar æ•°æ®")
    parser.add_argument("--bag", required=True, help="ROS2 bag ç›®å½•ï¼ˆå¯ä»¥æ˜¯å•ä¸ªbagç›®å½•æˆ–åŒ…å«å¤šä¸ªbagå­ç›®å½•çš„æ ¹ç›®å½•ï¼‰")
    parser.add_argument("--out", required=True, help="è¾“å‡ºæ ¹ç›®å½•")
    parser.add_argument(
        "--format", 
        required=True, 
        choices=['pcd_ascii', 'pcd_binary', 'bin'], 
        help="å¯¼å‡ºæ ¼å¼: pcd_ascii, pcd_binary (PCDæ ¼å¼çš„ASCII/äºŒè¿›åˆ¶), æˆ– bin (åŸå§‹äºŒè¿›åˆ¶ float32)"
    )
    args = parser.parse_args()

    bag_root = os.path.abspath(args.bag)
    out_root = os.path.abspath(args.out)
    export_format = args.format.lower()

    # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(bag_root):
        print(f"âŒ é”™è¯¯ï¼šè¾“å…¥è·¯å¾„ä¸å­˜åœ¨ï¼š{bag_root}")
        return

    # åˆ¤æ–­è¾“å…¥è·¯å¾„æœ¬èº«æ˜¯å¦æ˜¯ä¸€ä¸ªbagç›®å½•ï¼ˆåŒ…å«metadata.yamlï¼‰
    meta_file = os.path.join(bag_root, "metadata.yaml")
    if os.path.exists(meta_file):
        # å•ç›®å½•æ¨¡å¼ï¼šç›´æ¥å¤„ç†è¿™ä¸ªç›®å½•
        print(f"âœ… è¾“å…¥è·¯å¾„æ˜¯å•ä¸ªbagç›®å½•ï¼š{bag_root}")
        bag_paths = [bag_root]
    else:
        # å¤šç›®å½•æ¨¡å¼ï¼šéå†å­ç›®å½•
        print(f"ğŸ“ æŒ‰å¤šç›®å½•æ¨¡å¼å¤„ç†ï¼šéå† {bag_root} çš„å­ç›®å½•")
        bag_paths = []
        
        try:
            entries = os.listdir(bag_root)
        except Exception as e:
            print(f"âŒ æ— æ³•è¯»å–ç›®å½• {bag_root}: {e}")
            return
        
        if not entries:
            print(f"âš ï¸  ç›®å½•ä¸ºç©ºï¼š{bag_root}")
            return
        
        # éå†å­ç›®å½•ï¼ŒæŸ¥æ‰¾bagç›®å½•
        bag_count = 0
        for entry in sorted(entries):
            bag_path = os.path.join(bag_root, entry)
            
            # åªå¤„ç†ç›®å½•
            if not os.path.isdir(bag_path):
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„bagç›®å½•
            meta_file = os.path.join(bag_path, "metadata.yaml")
            if not os.path.exists(meta_file):
                # ä¸æ˜¯bagç›®å½•ï¼Œè·³è¿‡
                continue
            
            bag_paths.append(bag_path)
            bag_count += 1
            print(f"  æ‰¾åˆ°bagç›®å½• {bag_count}: {entry}")
        
        if bag_count == 0:
            print(f"âš ï¸  è­¦å‘Šï¼šåœ¨ {bag_root} ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„bagç›®å½•")
            print(f"   æ£€æŸ¥ç›®å½•ç»“æ„ï¼šåº”æœ‰å­ç›®å½•ï¼Œæ¯ä¸ªå­ç›®å½•åŒ…å« metadata.yaml")
            return

    print(f"æ€»è®¡æ‰¾åˆ° {len(bag_paths)} ä¸ªbagç›®å½•")
    
    # å¤„ç†æ¯ä¸ªbagç›®å½•
    for bag_path in bag_paths:
        print(f"\n" + "="*80)
        print(f"[INFO] å¼€å§‹å¯¼å‡º bag: {bag_path}")
        print(f"[INFO] å¯¼å‡ºæ ¼å¼: {export_format.upper()}")
        print("="*80)

        # ä¸ºè¯¥ bag åˆ›å»ºç‹¬ç«‹è¾“å‡ºè·¯å¾„
        # ä½¿ç”¨bagç›®å½•çš„åç§°ä½œä¸ºè¾“å‡ºå­ç›®å½•å
        bag_out_dir = os.path.join(out_root)
        
        # å¦‚æœè¾“å‡ºç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼ˆä¿æŒä¸åŸå§‹é€»è¾‘ä¸€è‡´ï¼‰
        # if os.path.exists(bag_out_dir):
        #     print(f"âš ï¸  è¾“å‡ºç›®å½•å·²å­˜åœ¨ï¼Œåˆ é™¤ï¼š{bag_out_dir}")
        #     shutil.rmtree(bag_out_dir)
        
        os.makedirs(bag_out_dir, exist_ok=True)

        # è°ƒç”¨å¯¼å‡ºå‡½æ•°
        export_one_bag(bag_path, bag_out_dir, export_format)

    print("\n" + "="*80)
    print("âœ… æ‰€æœ‰ bag å¯¼å‡ºå®Œæˆï¼")
    print("="*80)

if __name__ == "__main__":
    main()