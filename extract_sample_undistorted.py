#!/usr/bin/env python3

import os
import json
import shutil
import argparse
from datetime import datetime, timedelta

# --- é…ç½®å‚æ•° ---
OUTPUT_DIR_NAME = 'samples'
BASE_LASER_TOPIC = 'iv_points_front_mid'
TIME_INTERVAL_MS = 480  # å…³é”®å¸§é—´éš”ï¼š500æ¯«ç§’
MAX_TIME_DIFF_MS = 600  # åŒä¸€å…³é”®å¸§å†…å„ä¼ æ„Ÿå™¨ä¹‹é—´çš„æœ€å¤§æ—¶é—´å·®ï¼ˆæ¯«ç§’ï¼‰

# æ‰€æœ‰æ•°æ®ç›®å½•
ALL_DIRS = {
    'camera_cam_3M_front', 'camera_cam_3M_left', 'camera_cam_3M_rear',
    'camera_cam_3M_right', 'camera_cam_8M_pt_front', 'camera_cam_8M_wa_front',
    'iv_points_front_left', 'iv_points_front_mid', 'iv_points_front_right',
    'iv_points_rear_left', 'iv_points_rear_right',
    'iv_points_left_mid', 'iv_points_right_mid'
}

# å›¾åƒç›®å½•
IMAGE_TOPICS = [d for d in ALL_DIRS if d.startswith('camera_cam')]
# æ¿€å…‰é›·è¾¾ç›®å½•
LIDAR_TOPICS = [d for d in ALL_DIRS if d.startswith('iv_points')]
# æ‰€æœ‰éœ€è¦å¤„ç†çš„ Topic
ALL_TOPICS_TO_PROCESS = IMAGE_TOPICS + LIDAR_TOPICS

# å›¾åƒæ•°æ®å®é™…æ‰€åœ¨çš„å­ç›®å½•å
IMAGE_SUBDIR = 'scale_0.20' 
# æ¿€å…‰é›·è¾¾æ•°æ®å®é™…æ‰€åœ¨çš„å­ç›®å½•å
LIDAR_SUBDIR = 'pcd_binary'
INS_FILE_NAME = 'ins.json'


# --- å·¥å…·å‡½æ•° ---

def parse_filename_timestamp(filename):
    """
    ä»æ–‡ä»¶åè§£æå‡º datetime å¯¹è±¡ã€‚
    æ”¯æŒæ ¼å¼: 
    1. '20251104_155912_894.pcd' (æ¿€å…‰é›·è¾¾)
    2. '20251104_155913_034_scale_0.20_undistorted.jpg' (å»ç•¸å˜å›¾åƒ)
    """
    try:
        base_name = os.path.splitext(filename)[0]
        
        # 1. å¤„ç†å»ç•¸å˜å›¾åƒæ–‡ä»¶å: ç§»é™¤ '_scale_0.20_undistorted' åç¼€
        if base_name.endswith('_scale_0.20_undistorted'):
            # æå–æ—¶é—´æˆ³éƒ¨åˆ†: '20251104_155913_034'
            timestamp_str = base_name.rsplit('_scale_0.20_undistorted', 1)[0]
        else:
            # 2. å¤„ç†æ ‡å‡†æ—¶é—´æˆ³æ–‡ä»¶å (å¦‚æ¿€å…‰é›·è¾¾æ–‡ä»¶)
            timestamp_str = base_name

        # æ ¼å¼: YYYYMMDD_HHMMSS_mmm
        dt_object = datetime.strptime(timestamp_str, '%Y%m%d_%H%M%S_%f')
        return dt_object
    except ValueError:
        print(f"Warning: Could not parse timestamp from filename: {filename}")
        return None

def find_nearest_file_in_time_window(target_dt, file_list_with_dt, time_window_ms):
    """
    åœ¨æ—¶é—´çª—å£å†…å¯»æ‰¾æœ€æ¥è¿‘çš„æ–‡ä»¶ã€‚
    è¿”å› (æ–‡ä»¶å, datetime_object, æ—¶é—´å·®æ¯«ç§’æ•°) æˆ– (None, None, None)
    """
    if not file_list_with_dt:
        return None, None, None
    
    time_window = timedelta(milliseconds=time_window_ms)
    half_window = timedelta(milliseconds=time_window_ms/2)
    
    # é¦–å…ˆå¯»æ‰¾æ—¶é—´çª—å£å†…çš„æ–‡ä»¶
    candidates = []
    for filename, dt in file_list_with_dt:
        time_diff = abs((dt - target_dt).total_seconds() * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        if time_diff <= time_window_ms/2:  # åœ¨æ—¶é—´çª—å£å†…
            candidates.append((filename, dt, time_diff))
    
    if candidates:
        # é€‰æ‹©æ—¶é—´çª—å£å†…æœ€æ¥è¿‘çš„æ–‡ä»¶
        candidates.sort(key=lambda x: x[2])  # æŒ‰æ—¶é—´å·®æ’åº
        return candidates[0]
    else:
        # å¦‚æœæ²¡æœ‰åœ¨æ—¶é—´çª—å£å†…çš„æ–‡ä»¶ï¼Œè¿”å›æœ€æ¥è¿‘çš„ä¸€ä¸ª
        min_diff = float('inf')
        nearest = None
        nearest_dt = None
        
        for filename, dt in file_list_with_dt:
            time_diff = abs((dt - target_dt).total_seconds() * 1000)
            if time_diff < min_diff:
                min_diff = time_diff
                nearest = filename
                nearest_dt = dt
        
        return nearest, nearest_dt, min_diff

def find_consistent_frame_files(base_dt, all_topic_files_dt, max_time_diff_ms):
    """
    å¯»æ‰¾ä¸åŸºå‡†æ—¶é—´ä¸€è‡´çš„æ‰€æœ‰ä¼ æ„Ÿå™¨æ–‡ä»¶ã€‚
    è¿”å›å­—å…¸: {topic: (filename, timestamp, time_diff_ms)} å’Œ å¹³å‡æ—¶é—´æˆ³
    """
    result = {}
    time_diffs = []
    valid_topics = []
    
    # é¦–å…ˆç¡®ä¿åŸºå‡†æ¿€å…‰é›·è¾¾æœ‰æ–‡ä»¶
    base_topic = BASE_LASER_TOPIC
    if base_topic in all_topic_files_dt:
        base_files = all_topic_files_dt[base_topic]
        base_match, base_match_dt, base_diff = find_nearest_file_in_time_window(
            base_dt, [(fn, dt) for fn, dt, _ in base_files], max_time_diff_ms
        )
        
        if base_match:
            result[base_topic] = (base_match, base_match_dt, base_diff)
            time_diffs.append(base_diff)
            valid_topics.append(base_topic)
        else:
            return None, None
    
    # è·å–å®é™…åŒ¹é…åˆ°çš„åŸºå‡†æ—¶é—´
    actual_base_dt = result[base_topic][1] if base_topic in result else base_dt
    
    # å¯¹å…¶ä»–ä¼ æ„Ÿå™¨ï¼ŒåŸºäºå®é™…åŒ¹é…åˆ°çš„åŸºå‡†æ—¶é—´è¿›è¡ŒåŒ¹é…
    for topic in ALL_TOPICS_TO_PROCESS:
        if topic == base_topic:
            continue
            
        if topic in all_topic_files_dt:
            topic_files = all_topic_files_dt[topic]
            match, match_dt, time_diff = find_nearest_file_in_time_window(
                actual_base_dt, [(fn, dt) for fn, dt, _ in topic_files], max_time_diff_ms
            )
            
            if match and time_diff <= max_time_diff_ms:
                result[topic] = (match, match_dt, time_diff)
                time_diffs.append(time_diff)
                valid_topics.append(topic)
    
    # è®¡ç®—å¹³å‡æ—¶é—´æˆ³ï¼ˆä½¿ç”¨æœ‰æ•ˆæ–‡ä»¶çš„æ—¶é—´æˆ³ï¼‰
    if valid_topics:
        timestamps = [result[topic][1] for topic in valid_topics]
        avg_timestamp = timestamps[0]  # ç®€å•èµ·è§ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆæ—¶é—´æˆ³
        
        # æˆ–è€…å¯ä»¥è®¡ç®—å¹³å‡æ—¶é—´ï¼ˆæ›´å¤æ‚ä½†æ›´ç²¾ç¡®ï¼‰
        # total_seconds = sum(ts.timestamp() for ts in timestamps)
        # avg_timestamp = datetime.fromtimestamp(total_seconds / len(timestamps))
        
        return result, avg_timestamp
    
    return None, None

def find_nearest_ins_record(target_dt, all_ins_data, max_time_diff_ms):
    """
    å¯»æ‰¾æœ€æ¥è¿‘çš„INSè®°å½•ã€‚
    è¿”å› (timestamp_str, datetime_object, æ—¶é—´å·®æ¯«ç§’æ•°)
    """
    if not all_ins_data:
        return None, None, None
    
    min_diff = float('inf')
    nearest_ts = None
    nearest_dt = None
    
    for ts_str, dt_obj in all_ins_data.items():
        time_diff = abs((dt_obj - target_dt).total_seconds() * 1000)
        if time_diff < min_diff:
            min_diff = time_diff
            nearest_ts = ts_str
            nearest_dt = dt_obj
    
    if nearest_ts and min_diff <= max_time_diff_ms:
        return nearest_ts, nearest_dt, min_diff
    
    return None, None, None


# --- ä¸»è¦æµç¨‹ ---

def generate_key_frames(root_dir, copy_sample, max_time_diff_ms):
    """
    æ ¹æ®éœ€æ±‚ç”Ÿæˆå…³é”®å¸§ï¼Œæ‹·è´æ–‡ä»¶å¹¶ç”Ÿæˆ JSON è®°å½•ã€‚
    """
    ROOT_DIR = root_dir
    OUTPUT_DIR = os.path.join(ROOT_DIR, OUTPUT_DIR_NAME)
    INS_FILE = os.path.join(ROOT_DIR, INS_FILE_NAME)
    JSON_OUTPUT_FILE = os.path.join(ROOT_DIR, 'sample.json')
    
    print(f"ğŸš€ å¼€å§‹å¤„ç†ï¼Œæ ¹ç›®å½•: {ROOT_DIR}")
    print(f"ğŸ“ æ—¶é—´ä¸€è‡´æ€§é˜ˆå€¼: {max_time_diff_ms}ms")

    # --- 1. å‡†å¤‡è¾“å‡ºç›®å½•ç»“æ„ ---
    if copy_sample:
        if os.path.exists(OUTPUT_DIR):
            shutil.rmtree(OUTPUT_DIR)
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        
        for topic in ALL_TOPICS_TO_PROCESS:
            os.makedirs(os.path.join(OUTPUT_DIR, topic), exist_ok=True)
        print(f"âœ… åˆ›å»ºè¾“å‡ºç›®å½•: {OUTPUT_DIR} åŠå…¶æ‰€æœ‰ Topic å­ç›®å½•ã€‚")
    else:
        print("â„¹ï¸ è·³è¿‡åˆ›å»º/æ¸…ç† samples ç›®å½•å’Œå­ç›®å½• (--copy_sample ä¸º False)ã€‚")

    # --- 2. é€‰å‡ºåŸºå‡†æ¿€å…‰é›·è¾¾å…³é”®å¸§æ—¶é—´æˆ³ ---
    base_lidar_path = os.path.join(ROOT_DIR, BASE_LASER_TOPIC, LIDAR_SUBDIR)
    if not os.path.isdir(base_lidar_path):
        print(f"âŒ é”™è¯¯: åŸºå‡†æ¿€å…‰é›·è¾¾æ•°æ®ç›®å½•ä¸å­˜åœ¨: {base_lidar_path}")
        return

    all_base_lidar_files_with_dt = []
    for filename in os.listdir(base_lidar_path):
        if filename.endswith('.pcd'):
            dt = parse_filename_timestamp(filename)
            if dt:
                all_base_lidar_files_with_dt.append((filename, dt))

    if not all_base_lidar_files_with_dt:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°ä»»ä½•åŸºå‡†æ¿€å…‰é›·è¾¾æ–‡ä»¶ã€‚")
        return

    all_base_lidar_files_with_dt.sort(key=lambda x: x[1])
    
    # é€‰æ‹©å…³é”®å¸§ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    key_frames_dt = []
    first_frame = all_base_lidar_files_with_dt[0]
    key_frames_dt.append(first_frame[1])
    last_key_frame_dt = first_frame[1]
    time_delta = timedelta(milliseconds=TIME_INTERVAL_MS)

    for _, dt in all_base_lidar_files_with_dt[1:]:
        if dt >= last_key_frame_dt + time_delta:
            key_frames_dt.append(dt)
            last_key_frame_dt = dt
    
    print(f"âœ… åˆæ­¥é€‰å‡º {len(key_frames_dt)} ä¸ªåŸºå‡†å…³é”®å¸§æ—¶é—´æˆ³ (é—´éš” {TIME_INTERVAL_MS}ms)")

    # --- 3. å‡†å¤‡æ‰€æœ‰å¾…åŒ¹é… Topic çš„æ–‡ä»¶æ—¶é—´æˆ³åˆ—è¡¨ ---
    all_topic_files_dt = {}
    
    for topic in ALL_TOPICS_TO_PROCESS:
        is_lidar = topic in LIDAR_TOPICS
        
        if is_lidar:
            topic_path = os.path.join(ROOT_DIR, topic, LIDAR_SUBDIR)
        else:
            topic_path = os.path.join(ROOT_DIR, topic, IMAGE_SUBDIR)
        
        all_topic_files_dt[topic] = []
        if os.path.isdir(topic_path):
            file_extension = '.pcd' if is_lidar else '.jpg'
            for filename in os.listdir(topic_path):
                if filename.endswith(file_extension):
                    dt = parse_filename_timestamp(filename) 
                    if dt:
                        all_topic_files_dt[topic].append((filename, dt, topic_path))
        else:
            print(f"Warning: Topic ç›®å½• {topic_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚")

    # --- 4. å‡†å¤‡ INS æ•°æ® ---
    all_ins_data = {}
    try:
        with open(INS_FILE, 'r', encoding='utf-8') as f:
            ins_records = json.load(f)

        if not isinstance(ins_records, list):
            ins_records = [ins_records]
            
        print(f"âœ… æˆåŠŸåŠ è½½ {len(ins_records)} æ¡ INS è®°å½•ã€‚")

        for ins_record in ins_records:
            timestamp_desc = ins_record.get('timestamp_desc')
            if timestamp_desc:
                try:
                    ins_dt = datetime.strptime(timestamp_desc, '%Y%m%d_%H%M%S_%f')
                    all_ins_data[timestamp_desc] = ins_dt
                except ValueError:
                    print(f"Warning: INSæ—¶é—´æˆ³æ ¼å¼é”™è¯¯: {timestamp_desc}")

    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: INS æ–‡ä»¶ä¸å­˜åœ¨: {INS_FILE}")
        return 
    except json.JSONDecodeError as e:
        print(f"âŒ é”™è¯¯: INS æ–‡ä»¶æ ¼å¼é”™è¯¯ (JSONDecodeError): {e}")
        return 

    if not all_ins_data:
        print("âŒ é”™è¯¯: INS æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ 'timestamp_desc' å­—æ®µã€‚")
        return

    # --- 5. è¿›è¡Œä¸€è‡´æ€§åŒ¹é…ã€æ‹·è´å’Œè®°å½• ---
    sample_records = []
    frame_id = 0
    skipped_frames = 0
    
    for lidar_dt in key_frames_dt:
        # å¯»æ‰¾æ—¶é—´ä¸€è‡´çš„æ‰€æœ‰ä¼ æ„Ÿå™¨æ–‡ä»¶
        consistent_files, avg_timestamp = find_consistent_frame_files(
            lidar_dt, all_topic_files_dt, max_time_diff_ms
        )
        
        if not consistent_files:
            print(f"Warning: æ— æ³•ä¸ºå…³é”®å¸§æ—¶é—´æˆ³ {lidar_dt} æ‰¾åˆ°æ—¶é—´ä¸€è‡´çš„ä¼ æ„Ÿå™¨æ–‡ä»¶ï¼Œè·³è¿‡è¯¥å¸§ã€‚")
            skipped_frames += 1
            continue
        
        # æ£€æŸ¥é™¤äº†camera_cam_8M_pt_frontå¤–ï¼Œå…¶ä»–topicæ˜¯å¦éƒ½æœ‰æ–‡ä»¶
        has_missing_required_topic = False
        for topic in ALL_TOPICS_TO_PROCESS:
            if topic != 'camera_cam_8M_pt_front' and topic not in consistent_files:
                print(f"Warning: å…³é”®å¸§æ—¶é—´æˆ³ {lidar_dt} ç¼ºå°‘å¿…è¦çš„topic '{topic}'ï¼Œè·³è¿‡è¯¥å¸§ã€‚")
                has_missing_required_topic = True
                break
        
        if has_missing_required_topic:
            skipped_frames += 1
            continue
        
        record = {}
        record['id'] = frame_id
        record['frame_timestamp'] = avg_timestamp.strftime('%Y%m%d_%H%M%S_%f')[:-3]  # ä¿ç•™æ¯«ç§’
        
        # è®°å½•å„ä¼ æ„Ÿå™¨æ–‡ä»¶
        all_found = True
        time_diff_sum = 0
        time_diff_count = 0
        
        for topic in ALL_TOPICS_TO_PROCESS:
            if topic in consistent_files:
                filename, file_dt, time_diff = consistent_files[topic]
                record[topic] = filename
                
                # ç»Ÿè®¡æ—¶é—´å·®
                time_diff_sum += time_diff
                time_diff_count += 1
                
                # æ‹·è´æ–‡ä»¶
                if copy_sample:
                    # æŸ¥æ‰¾åŸå§‹è·¯å¾„
                    src_info = next((item for item in all_topic_files_dt[topic] 
                                    if item[0] == filename), None)
                    if src_info:
                        _, _, src_topic_path = src_info
                        src_path = os.path.join(src_topic_path, filename)
                        dest_path = os.path.join(OUTPUT_DIR, topic, filename)
                        
                        if os.path.exists(src_path):
                            shutil.copy2(src_path, dest_path)
                        else:
                            print(f"Warning: æºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•æ‹·è´: {src_path}")
            else:
                # åªæœ‰camera_cam_8M_pt_frontå¯ä»¥æ ‡è®°ä¸ºNOT_FOUND
                record[topic] = "NOT_FOUND" if topic == 'camera_cam_8M_pt_front' else filename
        
        # åŒ¹é… INS è®°å½•
        if all_ins_data:
            ins_ts, ins_dt, ins_time_diff = find_nearest_ins_record(
                avg_timestamp, all_ins_data, max_time_diff_ms
            )
            
            if ins_ts:
                record['ins'] = ins_ts
                record['ins_time_diff_ms'] = round(ins_time_diff, 1)
            else:
                record['ins'] = "NOT_FOUND"
                record['ins_time_diff_ms'] = None
        else:
            record['ins'] = "NOT_FOUND"
            record['ins_time_diff_ms'] = None
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if time_diff_count > 0:
            record['avg_time_diff_ms'] = round(time_diff_sum / time_diff_count, 1)
            record['max_allowed_diff_ms'] = max_time_diff_ms
        
        sample_records.append(record)
        frame_id += 1
        
        # # æ‰“å°è¿›åº¦
        # if frame_id % 10 == 0:
        #     print(f"âœ… å·²å¤„ç† {frame_id} ä¸ªå…³é”®å¸§...")

    # --- 6. ç”Ÿæˆ JSON æ–‡ä»¶ ---
    with open(JSON_OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(sample_records, f, ensure_ascii=False, indent=4)
    
    print(f"\nğŸ‰ å…³é”®å¸§é€‰æ‹©å’Œè®°å½•å®Œæˆï¼")
    print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - åˆå§‹å…³é”®å¸§æ•°é‡: {len(key_frames_dt)}")
    print(f"   - æœ‰æ•ˆå…³é”®å¸§æ•°é‡: {len(sample_records)}")
    print(f"   - è·³è¿‡çš„å…³é”®å¸§: {skipped_frames}")
    
    if sample_records:
        avg_diffs = [r.get('avg_time_diff_ms', 0) for r in sample_records if 'avg_time_diff_ms' in r]
        if avg_diffs:
            print(f"   - å¹³å‡æ—¶é—´å·®: {sum(avg_diffs)/len(avg_diffs):.1f}ms")
    
    if copy_sample:
        print(f"ğŸ“‚ æ‰€æœ‰å…³é”®å¸§æ–‡ä»¶å·²æ‹·è´åˆ°: {OUTPUT_DIR} ä¸‹çš„å„è‡ª Topic ç›®å½•ä¸­ã€‚")
    else:
        print(f"ğŸ“‚ å·²è·³è¿‡æ–‡ä»¶æ‹·è´æ“ä½œã€‚")
    print(f"ğŸ“ å…³é”®å¸§è®°å½•æ–‡ä»¶å·²ç”Ÿæˆ: {JSON_OUTPUT_FILE}")


# --- å‘½ä»¤è¡Œå‚æ•°å¤„ç† ---
def main():
    parser = argparse.ArgumentParser(
        description="åŸºäºæ¿€å…‰é›·è¾¾æ—¶é—´æˆ³ï¼Œä»å¤šä¸ªä¼ æ„Ÿå™¨Topicä¸­æå–å…³é”®å¸§å¹¶ç”Ÿæˆè®°å½•æ–‡ä»¶ã€‚",
        formatter_class=argparse.RawTextHelpFormatter
    )
    
    parser.add_argument(
        'root_dir',
        type=str,
        help=(
            "æ•°æ®é›†çš„æ ¹ç›®å½•è·¯å¾„ï¼ŒåŒ…å«æ‰€æœ‰ sensor_datas çš„ Topic ç›®å½•å’Œ ins.json æ–‡ä»¶ã€‚\n"
            "ä¾‹å¦‚: /home/shucdong/workspace/dataset/test/sensor_datas"
        )
    )
    
    parser.add_argument(
        '--copy_sample',
        action='store_true',
        default=False,
        help=(
            "æ˜¯å¦å°†å…³é”®å¸§æ–‡ä»¶æ‹·è´åˆ° samples ç›®å½•ä¸‹ã€‚\n"
            "å¦‚æœè®¾ç½®æ­¤å‚æ•° (ä¾‹å¦‚: --copy_sample)ï¼Œåˆ™æ‰§è¡Œæ‹·è´æ“ä½œï¼›\n"
            "å¦‚æœçœç•¥æ­¤å‚æ•° (é»˜è®¤)ï¼Œåˆ™åªç”Ÿæˆ sample.json æ–‡ä»¶ã€‚"
        )
    )
    
    # å¯é€‰å‚æ•°ï¼šå¯ä»¥è°ƒæ•´æ—¶é—´å·®é˜ˆå€¼
    parser.add_argument(
        '--max_time_diff',
        type=int,
        default=MAX_TIME_DIFF_MS,
        help=f"åŒä¸€å…³é”®å¸§å†…å„ä¼ æ„Ÿå™¨ä¹‹é—´çš„æœ€å¤§æ—¶é—´å·®ï¼ˆæ¯«ç§’ï¼‰ï¼Œé»˜è®¤: {MAX_TIME_DIFF_MS}ms"
    )

    args = parser.parse_args()
    
    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°çš„æ—¶é—´å·®é˜ˆå€¼ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼
    max_time_diff_ms = args.max_time_diff
    
    if max_time_diff_ms != MAX_TIME_DIFF_MS:
        print(f"âš ï¸ ä½¿ç”¨è‡ªå®šä¹‰æ—¶é—´å·®é˜ˆå€¼: {max_time_diff_ms}ms")
    
    root_dir = args.root_dir.rstrip(os.sep)
    generate_key_frames(root_dir, args.copy_sample, max_time_diff_ms)

if __name__ == '__main__':
    main()
