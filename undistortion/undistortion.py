#!/usr/bin/env python3

import cv2
import numpy as np
import os
import sys
import json
import uuid
import re
import time
from collections import defaultdict
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing
import argparse # å¯¼å…¥argparseæ¨¡å—
from pathlib import Path
current_dir = Path(__file__).resolve().parent
workspace_dir = current_dir.parent
if str(workspace_dir) not in sys.path:
    sys.path.append(str(workspace_dir))

# ä» lidar_to_image.py åŠå…¶ä¾èµ–ä¸­å¯¼å…¥æ‰€éœ€çš„é…ç½®å’Œæ˜ å°„   
from config.lidar_calibrator import LIDAR_CONFIGS, get_lidar_extrinsics_config_id
from config.camera_calibrator import get_camera_extrinsics

# è®¾ç½®è¿›ç¨‹æ± çš„æœ€å¤§å·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ä½¿ç”¨CPUæ ¸å¿ƒæ•°ï¼‰
# ä¼˜åŒ–ï¼šä¿ç•™2ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿå’Œå…¶ä»–IOæ“ä½œï¼Œé¿å…ç³»ç»Ÿå¡æ­»
MAX_WORKERS = max(1, multiprocessing.cpu_count() - 2)
# å¦‚æœCPUæ ¸å¿ƒæ•°å¤ªå¤šï¼Œå¯ä»¥æ‰‹åŠ¨é™åˆ¶ï¼Œä¾‹å¦‚ï¼šMAX_WORKERS = 4

def compute_undistort_maps(K, D, is_fish):
    """
    é¢„è®¡ç®—å»ç•¸å˜æ˜ å°„è¡¨ (ä¼˜åŒ–ï¼šé¿å…æ¯å¸§é‡å¤è®¡ç®—)
    """
    Knew = K.copy()
    
    if is_fish == 1:
        DIM_target = (2400, 1600)
        Knew[0, 0] = 0.5 * K[0, 0]
        Knew[1, 1] = 0.5 * K[1, 1]
        Knew[0, 2] = DIM_target[0]/2
        Knew[1, 2] = DIM_target[1]/2
        map1, map2 = cv2.fisheye.initUndistortRectifyMap(
            K, D, np.eye(3), Knew, DIM_target, cv2.CV_16SC2
        )
        interpolation = cv2.INTER_CUBIC
    else:
        DIM_target = (5400, 2260)
        Knew[0, 0] = 1 * K[0, 0]
        Knew[1, 1] = 1 * K[1, 1]
        Knew[0, 2] = DIM_target[0]/2
        Knew[1, 2] = DIM_target[1]/2
        map1, map2 = cv2.initUndistortRectifyMap(
            K, D, np.eye(3), Knew, DIM_target, cv2.CV_16SC2
        )
        interpolation = cv2.INTER_LINEAR
        
    return map1, map2, Knew, interpolation

def apply_undistort(img, map1, map2, interpolation):
    """
    åº”ç”¨å»ç•¸å˜æ˜ å°„ (ä¼˜åŒ–ï¼šç›´æ¥ä½¿ç”¨é¢„è®¡ç®—çš„æ˜ å°„è¡¨)
    """
    undistorted_img = cv2.remap(
        img, map1, map2, 
        interpolation=interpolation,
        borderMode=cv2.BORDER_CONSTANT, 
        borderValue=(0, 0, 0)
    )
    return undistorted_img

def undistort_fish_optimized(img_path, K, D, DIM, is_fish, scale=0.5):
    """é±¼çœ¼ç›¸æœºå»ç•¸å˜ï¼ˆä¿æŒåŸæœ‰å®ç°ï¼‰"""
    img = cv2.imread(img_path)
    if img is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")
    
    h, w = img.shape[:2]
    
    if abs(w/h - DIM[0]/DIM[1]) > 0.01:
        print(f"è­¦å‘Š: å›¾åƒå®½é«˜æ¯”ä¸åŒ¹é…ï¼Œå°†è¿›è¡Œç¼©æ”¾")
        img = cv2.resize(img, DIM, interpolation=cv2.INTER_AREA)
    
    Knew = K.copy()

    if is_fish == 1:
            DIM = (2400, 1600)

            Knew[0, 0] = 0.5 * K[0, 0]
            Knew[1, 1] = 0.5 * K[1, 1]
            Knew[0, 2] = DIM[0]/2
            Knew[1, 2] = DIM[1]/2
            map1, map2 = cv2.fisheye.initUndistortRectifyMap(
        K, D, np.eye(3), Knew, DIM, cv2.CV_16SC2
    )
    
            undistorted_img = cv2.remap(
        img, map1, map2, 
        interpolation=cv2.INTER_CUBIC,
        borderMode=cv2.BORDER_CONSTANT, 
        borderValue=(0, 0, 0)
    )
    else:
            DIM = (5400, 2260)

            
        # ä½¿ç”¨è°ƒæ•´åçš„å†…å‚
            Knew = K.copy()
            Knew[0, 0] = 1 * K[0, 0]  # fx
            Knew[1, 1] = 1 * K[1, 1]  # fy  
            Knew[0, 2] = DIM[0]/2
            Knew[1, 2] = DIM[1]/2
            map1, map2 = cv2.initUndistortRectifyMap(
            K, D, np.eye(3), Knew, DIM, cv2.CV_16SC2
        )
            undistorted_img = cv2.remap(
            img, map1, map2, 
            interpolation=cv2.INTER_LINEAR,
            borderMode=cv2.BORDER_CONSTANT,
            borderValue=(0, 0, 0)
        )
            # undistorted_img = cv2.undistort(img, K, D, None, Knew)

    return undistorted_img, Knew

def crop_black_borders(
    img, 
    crop_factor=0.0, 
    non_black_thresh=1,
    return_borders=False
):
    """ä¿æŒåŸæœ‰é»‘è¾¹è£å‰ªåŠŸèƒ½"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    height, width = gray.shape
    
    row_left_points = []
    row_right_points = []
    col_top_points = []
    col_bottom_points = []
    
    for y in range(height):
        left_x = None
        for x in range(width):
            if gray[y, x] > non_black_thresh:
                left_x = x
                break
        if left_x is not None:
            row_left_points.append((left_x, y))
        
        right_x = None
        for x in range(width-1, -1, -1):
            if gray[y, x] > non_black_thresh:
                right_x = x
                break
        if right_x is not None:
            row_right_points.append((right_x, y))
    
    for x in range(width):
        top_y = None
        for y in range(height):
            if gray[y, x] > non_black_thresh:
                top_y = y
                break
        if top_y is not None:
            col_top_points.append((x, top_y))
        
        bottom_y = None
        for y in range(height-1, -1, -1):
            if gray[y, x] > non_black_thresh:
                bottom_y = y
                break
        if bottom_y is not None:
            col_bottom_points.append((x, bottom_y))
    
    if (len(row_left_points) == 0 or len(row_right_points) == 0 or
        len(col_top_points) == 0 or len(col_bottom_points) == 0):
        print("è­¦å‘Šï¼šæŸç»„è¾¹ç•Œç‚¹ä¸ºç©ºï¼Œè¿”å›åŸå›¾")
        if return_borders:
            return img, (0, 0, width-1, height-1)
        return img
    
    left_bound = max(row_left_points, key=lambda p: p[0])[0]
    right_bound = min(row_right_points, key=lambda p: p[0])[0]
    top_bound = max(col_top_points, key=lambda p: p[1])[1]
    bottom_bound = min(col_bottom_points, key=lambda p: p[1])[0]
    
    if (left_bound >= right_bound) or (top_bound >= bottom_bound):
        print("è­¦å‘Šï¼šç­›é€‰åè¾¹ç•Œæ— æ•ˆï¼Œè¿”å›åŸå›¾")
        if return_borders:
            return img, (0, 0, width-1, height-1)
        return img
    
    inner_width = right_bound - left_bound
    inner_height = bottom_bound - top_bound
    
    crop_x = int(inner_width * crop_factor)
    crop_y = int(inner_height * crop_factor)
    
    x_start = max(left_bound + crop_x, 0)
    y_start = max(top_bound + crop_y, 0)
    x_end = min(right_bound - crop_x, width - 1)
    y_end = min(bottom_bound - crop_y, height - 1)
    
    if x_end <= x_start:
        x_start, x_end = left_bound, right_bound
    if y_end <= y_start:
        y_start, y_end = top_bound, bottom_bound
    
    cropped_img = img[y_start:y_end+1, x_start:x_end+1]
    
    if return_borders:
        return cropped_img, (x_start, y_start, x_end, y_end)
    
    return cropped_img

def update_intrinsic_matrix_for_vertical_crop(K_cropped, vertical_crop_info):
    """ä¿æŒåŸæœ‰çºµå‘è£å‰ªå†…å‚æ›´æ–°åŠŸèƒ½"""
    top_crop, _ = vertical_crop_info
    
    K_final = K_cropped.copy()
    K_final[1, 2] -= top_crop
    
    return K_final

def vertical_crop_image(img, vertical_crop_ratio):
    """ä¿æŒåŸæœ‰çºµå‘è£å‰ªåŠŸèƒ½"""
    if vertical_crop_ratio == 0:
        return img, (0, 0)
    
    h, w = img.shape[:2]
    
    total_crop_pixels = int(h * vertical_crop_ratio)
    top_crop = total_crop_pixels // 2
    bottom_crop = total_crop_pixels - top_crop
    
    if top_crop + bottom_crop >= h:
        print(f"è­¦å‘Š: è£å‰ªæ¯”ä¾‹è¿‡å¤§({vertical_crop_ratio})ï¼Œå°†ä½¿ç”¨æœ€å¤§å¯ç”¨è£å‰ª")
        top_crop = h // 4
        bottom_crop = h // 4
    
    cropped_img = img[top_crop:h-bottom_crop, :]
    
    return cropped_img, (top_crop, bottom_crop)

def update_intrinsic_matrix(K_undistort, crop_borders):
    """ä¿æŒåŸæœ‰è£å‰ªè¾¹ç•Œå†…å‚æ›´æ–°åŠŸèƒ½"""
    x_start, y_start, _, _ = crop_borders
    K_cropped = K_undistort.copy()
    
    K_cropped[0, 2] -= x_start
    K_cropped[1, 2] -= y_start
    
    return K_cropped

def undistort_stand(img_path, K, D, DIM, scale=0.5, imshow=False):
    """ä¿æŒåŸæœ‰æ ‡å‡†å»ç•¸å˜åŠŸèƒ½"""
    img = cv2.imread(img_path)
    dim1 = img.shape[:2][::-1]
    assert dim1[0]/dim1[1] == DIM[0]/DIM[1], "Image to undistort needs same aspect ratio as calibration"
    if dim1[0] != DIM[0]:
        img = cv2.resize(img, DIM, interpolation=cv2.INTER_AREA)
    Knew = K.copy()
    if scale:
        Knew[(0,1), (0,1)] = scale * Knew[(0,1), (0,1)]
    map1, map2 = cv2.initUndistortRectifyMap(K, D, np.eye(3), Knew, DIM, cv2.CV_16SC2)
    undistorted_img = cv2.remap(img, map1, map2, interpolation=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT)
    if imshow:
        cv2.imshow("undistorted", undistorted_img)
    return undistorted_img, Knew

# **ä¿®æ”¹1ï¼šæ·»åŠ  vehicle_type å’Œ logtime å‚æ•°**
def generate_sensor_json_entry(folder_name, direction, K_matrix, translation, rotation, sensor_type="camera", vehicle_type="default", logtime="no_time"):
    """
    ç”Ÿæˆä¼ æ„Ÿå™¨é…ç½®JSONæ¡ç›®ï¼Œå¹¶æ·»åŠ  vehicle_type å’Œ logtime å­—æ®µã€‚
    """
    token = vehicle_type + '_' + logtime
    sensor_token = folder_name
    # token = f"/sensor/{sensor_type}/{direction}"
    # sensor_token = f"/sensor/{sensor_type}/{direction}/config"
    
    entry = {
        "token": f'{token}_{sensor_token}',
        "sensor_token": sensor_token,
        "translation": translation,
        "rotation": rotation,
        "camera_intrinsic": []
    }
    
    if sensor_type == "camera" and K_matrix is not None:
        entry["camera_intrinsic"] = K_matrix.tolist()
    
    return entry

# **ä¿®æ”¹2ï¼šæ·»åŠ  vehicle_type å’Œ logtime å‚æ•°**
def generate_lidar_placeholder_entries(count=5, vehicle_type="default", logtime="no_time"):
    """
    ç”ŸæˆLiDARå ä½ç¬¦æ¡ç›®ï¼Œå¹¶æ·»åŠ  vehicle_type å’Œ logtime å­—æ®µã€‚
    """
    lidar_entries = []

    token = f'{vehicle_type}_{logtime}'

    for topic in LIDAR_CONFIGS.keys():
        lidar_extrinsic = get_lidar_extrinsics_config_id(topic)
        r = lidar_extrinsic["ext_quaternion_xyzw"]
        entry = {
            "token": f"{token}_{topic}",
            "sensor_token": f'{topic}_config',
            "translation": lidar_extrinsic["translation"],
            "rotation": [r[3], r[0], r[1], r[2]],  # è½¬æ¢ä¸º [w, x, y, z] æ ¼å¼
            # "camera_intrinsic": [],
        }
        lidar_entries.append(entry)
    return lidar_entries

def center_crop_to_resolution(img, target_resolution):
    """
    æŒ‰ç›®æ ‡åˆ†è¾¨ç‡ä¸­å¿ƒè£å‰ªå›¾åƒï¼ˆæ— æ‹‰ä¼¸ï¼Œä»…è£å‰ªï¼‰
    :param img: è¾“å…¥å›¾åƒï¼ˆå»ç•¸å˜+é»‘è¾¹è£å‰ªåï¼‰
    :param target_resolution: ç›®æ ‡åˆ†è¾¨ç‡ (width, height)
    :return: è£å‰ªåçš„å›¾åƒ, è£å‰ªè¾¹ç•Œ (x_start, y_start, x_end, y_end)
    """
    img_h, img_w = img.shape[:2]
    target_w, target_h = target_resolution
    
    # æ£€æŸ¥ç›®æ ‡åˆ†è¾¨ç‡æ˜¯å¦å¤§äºåŸå›¾ï¼Œè‹¥å¤§äºåˆ™è¿”å›åŸå›¾ï¼ˆä¸æ‹‰ä¼¸ï¼‰
    if target_w >= img_w and target_h >= img_h:
        print(f"è­¦å‘Š: ç›®æ ‡åˆ†è¾¨ç‡{target_resolution}å¤§äºåŸå›¾åˆ†è¾¨ç‡({img_w}, {img_h})ï¼Œè¿”å›åŸå›¾")
        return img, (0, 0, img_w-1, img_h-1)
    
    # è®¡ç®—ä¸­å¿ƒè£å‰ªåç§»é‡
    x_offset = (img_w - target_w) // 2
    y_offset = (img_h - target_h) // 2
    
    # è®¡ç®—è£å‰ªè¾¹ç•Œ
    x_start = x_offset
    y_start = y_offset
    x_end = x_offset + target_w - 1
    y_end = y_offset + target_h - 1
    
    # è£å‰ªå›¾åƒ
    cropped_img = img[y_start:y_end+1, x_start:x_end+1]
    
    return cropped_img, (x_start, y_start, x_end, y_end)

def find_direction_folders(base_path):
    """
    åœ¨åŸºç›®å½•ä¸‹æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ–¹å‘æ ‡è¯†çš„æ–‡ä»¶å¤¹
    è¿”å›æ ¼å¼: [(æ–‡ä»¶å¤¹è·¯å¾„, æ–¹å‘åç§°, æ˜¯å¦ä¸º8Mç›¸æœº), ...]
    """
    direction_patterns = {
        'front': r'.*3M.*front.*',
        'left': r'.*3M.*left.*', 
        'right': r'.*3M.*right.*',
        'rear': r'.*3M.*rear.*',
        'front_8M': r'.*8M_wa.*front.*',
        'rear_8M': r'.*8M.*rear.*'
    }
    
    found_dirs = []
    
    # éå†åŸºç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹
    for root_dir in os.listdir(base_path):
        root_path = os.path.join(base_path, root_dir)
        if not os.path.isdir(root_path):
            continue
            
        print(f"æ­£åœ¨æ‰«æç›®å½•: {root_path}")
        
        # åœ¨å­æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾ç¬¦åˆæ–¹å‘æ¨¡å¼çš„æ–‡ä»¶å¤¹
        for item in os.listdir(root_path):
            item_path = os.path.join(root_path, item)
            if not os.path.isdir(item_path):
                continue
                
            # æ£€æŸ¥æ–‡ä»¶å¤¹åç§°æ˜¯å¦ç¬¦åˆæ–¹å‘æ¨¡å¼
            for direction, pattern in direction_patterns.items():
                if re.match(pattern, item, re.IGNORECASE):
                    is_8M = "8M" in direction
                    found_dirs.append((item_path, direction, is_8M))
                    print(f"  æ‰¾åˆ°æ–¹å‘æ–‡ä»¶å¤¹: {item} -> {direction} (8M: {is_8M})")
                    break
    if not found_dirs:
        print("è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•æ–¹å‘æ–‡ä»¶å¤¹ï¼Œè¯·æ£€æŸ¥ç›®å½•ç»“æ„å’Œå‘½å, å°è¯•ä»è¾“å…¥ç›®å½•ä¸­ç›´æ¥æŸ¥æ‰¾")
        # å°è¯•ä»è¾“å…¥ç›®å½•ä¸­ç›´æ¥æŸ¥æ‰¾æ–¹å‘æ–‡ä»¶å¤¹
        for item in os.listdir(base_path):
            item_path = os.path.join(base_path, item)
            if not os.path.isdir(item_path):
                continue
                
            for direction, pattern in direction_patterns.items():
                if re.match(pattern, item, re.IGNORECASE):
                    is_8M = "8M" in direction
                    found_dirs.append((item_path, direction, is_8M))
                    print(f"  æ‰¾åˆ°æ–¹å‘æ–‡ä»¶å¤¹: {item} -> {direction} (8M: {is_8M})")
                    break
    return found_dirs

# **ä¿®æ”¹3ï¼šæ·»åŠ  vehicle_type å’Œ logtime å‚æ•°**
def generate_scale_combined_json(output_dir, scale_value, all_camera_entries, vehicle_type, logtime):
    """
    ä¸ºæ¯ä¸ªscaleç”ŸæˆåŒ…å«æ‰€æœ‰ç›¸æœºæ–¹å‘å’Œé›·è¾¾é¢„ç•™ä½ç½®çš„æ€»å’ŒJSONæ–‡ä»¶
    """
    if not all_camera_entries:
        print(f"è­¦å‘Š: scale {scale_value} æ²¡æœ‰ç›¸æœºæ¡ç›®ï¼Œè·³è¿‡ç”Ÿæˆæ€»å’ŒJSON")
        return
    
    # å¤åˆ¶æ‰€æœ‰ç›¸æœºæ¡ç›®
    combined_entries = all_camera_entries.copy()
    
    # æ·»åŠ é›·è¾¾å ä½ç¬¦
    # **ä¼ é€’ vehicle_type å’Œ logtime**
    lidar_entries = generate_lidar_placeholder_entries(
        count=5, 
        vehicle_type=vehicle_type, 
        logtime=logtime
    )
    combined_entries.extend(lidar_entries)
    
    # ä¿å­˜æ€»å’ŒJSONæ–‡ä»¶
    json_filename = f"sensor_config_combined_scale_{scale_value}.json"
    json_path = os.path.join(output_dir, json_filename)
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(combined_entries, f, indent=4, ensure_ascii=False)
    
    print(f"å·²ç”Ÿæˆscale {scale_value} æ€»å’Œä¼ æ„Ÿå™¨é…ç½®JSON: {json_path}")
    print(f"  - åŒ…å« {len(all_camera_entries)} ä¸ªç›¸æœºå’Œ 5 ä¸ªLiDAR")

# **ä¿®æ”¹4ï¼šæ·»åŠ  logtime å‚æ•°**
def process_single_direction(
    direction_info, params_dir, output_base, scales, 
    crop_factor, target_resolutions, enable_resolution_crop,
    vehicle_type, # è½¦è¾†ç±»å‹å‚æ•°
    logtime # æ–°å¢ logtime å‚æ•°
):
    """
    å¤„ç†å•ä¸ªæ–¹å‘æ–‡ä»¶å¤¹çš„å‡½æ•°ï¼ˆç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰
    :param direction_info: å•ä¸ªæ–¹å‘çš„ä¿¡æ¯ tuple (folder_path, direction, is_8M_camera)
    :return: è¯¥æ–¹å‘çš„ç›¸æœºæ¡ç›®å­—å…¸ {scale: [camera_entry]}
    """
    folder_path, direction, is_8M_camera = direction_info
    direction_camera_entries = defaultdict(list)
    
    try:
        # åˆ¤æ–­æ˜¯å¦ä¸ºé±¼çœ¼ç›¸æœº
        is_fisheye = not is_8M_camera
        direction_start_time = time.time()
        
        print(f"\n{'='*50}")
        print(f"[è¿›ç¨‹ {os.getpid()}] å¤„ç†æ–¹å‘: {direction}")
        print(f"  - è½¦è¾†ç±»å‹: {vehicle_type}") 
        print(f"  - LogTime: {logtime}") # æ‰“å°æ–°å¢å‚æ•°
        print(f"  - æ–‡ä»¶å¤¹è·¯å¾„: {folder_path}")
        print(f"  - æ˜¯å¦ä¸º8Mç›¸æœº: {is_8M_camera} (ä½¿ç”¨é’ˆå­”å»ç•¸å˜)")
        print(f"  - æ˜¯å¦ä¸ºé±¼çœ¼ç›¸æœº: {is_fisheye} (ä½¿ç”¨é±¼çœ¼å»ç•¸å˜)")
        
        # åŠ è½½å¯¹åº”çš„å†…å‚æ–‡ä»¶ï¼ˆå‚æ•°è¯»å–æ–¹å¼ä¸å˜ï¼‰
        if is_8M_camera:
            k_path = os.path.join(params_dir, f"camera_8M_front_K.npy")
            d_path = os.path.join(params_dir, f"camera_8M_front_D.npy")
        else:
            # å¯¹äº3Mç›¸æœºï¼Œå»æ‰_8Måç¼€
            base_direction = direction.replace('_8M', '') if direction.endswith('_8M') else direction
            k_path = os.path.join(params_dir, f"camera_{base_direction}_3M_K.npy")
            d_path = os.path.join(params_dir, f"camera_{base_direction}_3M_D.npy")
        
        if not os.path.exists(k_path) or not os.path.exists(d_path):
            print(f"è­¦å‘Š: {direction} æ–¹å‘çš„å‚æ•°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            print(f"  Kæ–‡ä»¶è·¯å¾„: {k_path}")
            print(f"  Dæ–‡ä»¶è·¯å¾„: {d_path}")
            return direction_camera_entries
        
        K_original = np.load(k_path)
        D = np.load(d_path)
        print(f"æˆåŠŸåŠ è½½ {direction} æ–¹å‘çš„å‚æ•°: K.shape={K_original.shape}, D.shape={D.shape}")
        
        # è·å–æ–‡ä»¶å¤¹åç§°ç”¨äºæ„å»ºè¾“å‡ºè·¯å¾„
        folder_name = os.path.basename(folder_path)
        parent_folder = os.path.basename(os.path.dirname(folder_path))
        
        # å›¾åƒç›®å½•å°±æ˜¯æ‰¾åˆ°çš„æ–‡ä»¶å¤¹è·¯å¾„
        img_dir = folder_path
        img_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
        img_files = [f for f in os.listdir(img_dir) if f.lower().endswith(img_extensions)]
        
        if not img_files:
            print(f"è­¦å‘Š: {img_dir} ç›®å½•ä¸‹æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return direction_camera_entries
        
        total_images = len(img_files)
        print(f"ğŸ“¸ æ‰¾åˆ° {total_images} å¼ å›¾ç‰‡")
        
        # è·å–å¤–å‚
        extrinsics = get_camera_extrinsics(direction)
        translation = extrinsics["translation"]
        r = extrinsics["rotation"] # xyzw
        rotation = [r[3], r[0], r[1], r[2]] # è½¬æ¢ä¸º wxyz
        
        # é¢„è®¡ç®—å»ç•¸å˜æ˜ å°„è¡¨ï¼ˆä¼˜åŒ–ï¼šæå–åˆ°å¾ªç¯å¤–ï¼‰
        is_fish_param = 2 if is_8M_camera else 1
        map1, map2, K_undistort_base, interpolation = compute_undistort_maps(K_original, D, is_fish_param)

        for scale in scales:
            scale_start_time = time.time()
            print(f"\n--- [è¿›ç¨‹ {os.getpid()}] æ­£åœ¨å¤„ç† scale = {scale} ---")
            
            # æ„å»ºè¾“å‡ºç›®å½•
            # output_dir = os.path.join(output_base, parent_folder, folder_name, f"scale_{scale:.2f}")
            output_dir = os.path.join(output_base, folder_name, f"scale_{scale:.2f}")
            res_crop_dir = os.path.join(output_dir, "resolution_crops")
            os.makedirs(output_dir, exist_ok=True)
            if enable_resolution_crop:
                os.makedirs(res_crop_dir, exist_ok=True)
            
            K_cropped = None
            crop_borders = None
            K_undistort = None
            
            # å¤„ç†å›¾åƒæ–‡ä»¶
            print(f"\nâ³ å¼€å§‹å¤„ç† {total_images} å¼ å›¾ç‰‡...")
            frame_start_time = time.time()
            processed_count = 0
            last_update_time = time.time()
            update_interval = 0.5  # æ¯0.5ç§’æ›´æ–°ä¸€æ¬¡è¿›åº¦ï¼Œå‡å°‘IOå¼€é”€
            
            for idx, img_file in enumerate(img_files):
                img_start_time = time.time()
                img_path = os.path.join(img_dir, img_file)
                
                sample_img = cv2.imread(img_path)
                if sample_img is None:
                    print(f"è·³è¿‡æ— æ³•è¯»å–çš„å›¾åƒ: {img_path}")
                    continue
                h, w = sample_img.shape[:2]
                DIM = (w, h)
                
                # ä¼˜åŒ–ï¼šç›´æ¥åº”ç”¨é¢„è®¡ç®—çš„æ˜ å°„è¡¨
                undistorted_img = apply_undistort(sample_img, map1, map2, interpolation)
                K_undistort = K_undistort_base.copy()
                
                # é»‘è¾¹è£å‰ªï¼ˆå¯é€‰ï¼‰
                if crop_factor > 0:
                    undistorted_img, crop_borders = crop_black_borders(
                        undistorted_img, crop_factor=crop_factor, return_borders=True
                    )
                    # æ›´æ–°é»‘è¾¹è£å‰ªåçš„å†…å‚
                    if K_undistort is not None and crop_borders is not None:
                        K_cropped = update_intrinsic_matrix(K_undistort, crop_borders)
                else:
                    crop_borders = (0, 0, undistorted_img.shape[1]-1, undistorted_img.shape[0]-1)
                    K_cropped = K_undistort.copy()
                
                # ä¿å­˜å»ç•¸å˜åŸå›¾ï¼ˆé»‘è¾¹è£å‰ªåï¼‰
                filename, ext = os.path.splitext(img_file)
                original_output_name = f"{filename}_scale_{scale:.2f}_undistorted{ext}"
                original_output_path = os.path.join(output_dir, original_output_name)
                cv2.imwrite(original_output_path, undistorted_img)
                # print(f"[è¿›ç¨‹ {os.getpid()}] å·²ä¿å­˜å»ç•¸å˜åŸå›¾: {original_output_path}")
                
                # æ›´æ–°è¿›åº¦ç»Ÿè®¡
                processed_count += 1
                current_time = time.time()
                
                # åªåœ¨è¾¾åˆ°æ›´æ–°é—´éš”æˆ–æœ€åä¸€å¼ æ—¶æ›´æ–°è¿›åº¦æ¡ï¼ˆå‡å°‘IOå¼€é”€ï¼‰
                if (current_time - last_update_time >= update_interval) or (processed_count == total_images):
                    total_elapsed = current_time - frame_start_time
                    avg_time_per_img = total_elapsed / processed_count
                    fps = processed_count / total_elapsed if total_elapsed > 0 else 0
                    eta_seconds = avg_time_per_img * (total_images - processed_count)
                    
                    # æ˜¾ç¤ºè¿›åº¦æ¡
                    progress_pct = (processed_count / total_images) * 100
                    bar_length = 30
                    filled_length = int(bar_length * processed_count / total_images)
                    bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
                    
                    # æ„å»ºè¿›åº¦ä¿¡æ¯ï¼ˆå›ºå®šå®½åº¦é¿å…è·³åŠ¨ï¼‰
                    progress_info = (
                        f"[è¿›ç¨‹ {os.getpid()}] "
                        f"{processed_count:>4}/{total_images:<4} "
                        f"({progress_pct:>5.1f}%) | "
                        f"{fps:>5.2f} fps | "
                        f"ETA: {eta_seconds:>5.1f}s"
                    )
                    
                    # ä¼˜åŒ–ï¼šå¤šè¿›ç¨‹ç¯å¢ƒä¸‹é¿å…ä½¿ç”¨ \rï¼Œæ”¹ä¸ºæ¯éš”ä¸€å®šæ—¶é—´æ‰“å°ä¸€è¡Œ
                    # ä½¿ç”¨\rå›è½¦+æ¸…ç©ºé¿å…æ®‹ç•™ï¼Œ\033[Kæ¸…ç©ºåˆ°è¡Œå°¾
                    # sys.stdout.write(f"\r{progress_info}\033[K")
                    # sys.stdout.flush()
                    print(progress_info)
                    
                    last_update_time = current_time
                
                # åˆ†è¾¨ç‡è£å‰ªï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if enable_resolution_crop:
                    for target_res in target_resolutions:
                        target_w, target_h = target_res
                        res_name = f"{target_w}x{target_h}"
                        
                        # æ¯ä¸ªåˆ†è¾¨ç‡å•ç‹¬å»ºæ–‡ä»¶å¤¹
                        res_dir = os.path.join(res_crop_dir, res_name)
                        os.makedirs(res_dir, exist_ok=True)
                        
                        # ä¸­å¿ƒè£å‰ªåˆ°ç›®æ ‡åˆ†è¾¨ç‡
                        res_cropped_img, res_crop_borders = center_crop_to_resolution(
                            undistorted_img, target_res
                        )
                        
                        # æ›´æ–°åˆ†è¾¨ç‡è£å‰ªåçš„å†…å‚
                        x_start_res, y_start_res, _, _ = res_crop_borders
                        K_res_cropped = K_cropped.copy()
                        K_res_cropped[0, 2] -= x_start_res
                        K_res_cropped[1, 2] -= y_start_res
                        
                        # ä¿å­˜åˆ†è¾¨ç‡è£å‰ªåçš„å›¾åƒ
                        res_output_name = f"{filename}_scale_{scale:.2f}_crop_{res_name}{ext}"
                        res_output_path = os.path.join(res_dir, res_output_name)
                        cv2.imwrite(res_output_path, res_cropped_img)
                        # print(f"[è¿›ç¨‹ {os.getpid()}]   - å·²ä¿å­˜{res_name}è£å‰ªå›¾: {res_output_path}")
                        
                        # ä¿å­˜åˆ†è¾¨ç‡è£å‰ªåçš„å†…å‚
                        res_k_suffix = "_8M_K_res_cropped.npy" if is_8M_camera else "_3M_K_res_cropped.npy"
                        res_k_path = os.path.join(res_dir, f"camera_{direction}_scale_{scale:.2f}_{res_name}{res_k_suffix}")
                        np.save(res_k_path, K_res_cropped)
                        # print(f"[è¿›ç¨‹ {os.getpid()}]   - å·²ä¿å­˜{res_name}å†…å‚: {res_k_path}")
            
            # æ¢è¡Œç»“æŸè¿›åº¦æ¡
            print()  
            
            # è¾“å‡ºscaleçº§åˆ«ç»Ÿè®¡
            scale_elapsed = time.time() - scale_start_time
            scale_fps = total_images / scale_elapsed if scale_elapsed > 0 else 0
            print(f"\nâœ… Scale {scale} å¤„ç†å®Œæˆ:")
            print(f"   - å¤„ç†å›¾ç‰‡: {total_images} å¼ ")
            print(f"   - æ€»è€—æ—¶: {scale_elapsed:.2f}s")
            print(f"   - å¹³å‡é€Ÿåº¦: {scale_fps:.2f} fps")
            print(f"   - å¹³å‡æ¯å¼ : {scale_elapsed/total_images:.3f}s")
            
            # ä¿å­˜åŸºç¡€å†…å‚æ–‡ä»¶
            if K_undistort is not None:
                # åŸå§‹å†…å‚
                k_original_suffix = "_8M_K_original.npy" if is_8M_camera else "_3M_K_original.npy"
                k_original_path = os.path.join(output_dir, f"camera_{direction}_scale_{scale:.2f}{k_original_suffix}")
                np.save(k_original_path, K_original)
                
                # å»ç•¸å˜åå†…å‚
                k_undistort_suffix = "_8M_K_undistort.npy" if is_8M_camera else "_3M_K_undistort.npy"
                k_undistort_path = os.path.join(output_dir, f"camera_{direction}_scale_{scale:.2f}{k_undistort_suffix}")
                np.save(k_undistort_path, K_undistort)
                
                # é»‘è¾¹è£å‰ªåå†…å‚
                if K_cropped is not None:
                    k_cropped_suffix = "_8M_K_cropped.npy" if is_8M_camera else "_3M_K_cropped.npy"
                    k_cropped_path = os.path.join(output_dir, f"camera_{direction}_scale_{scale:.2f}{k_cropped_suffix}")
                    np.save(k_cropped_path, K_cropped)
                
                print(f"[è¿›ç¨‹ {os.getpid()}] å·²ä¿å­˜åŸå§‹å†…å‚: {k_original_path}")
                print(f"[è¿›ç¨‹ {os.getpid()}] å·²ä¿å­˜å»ç•¸å˜åå†…å‚: {k_undistort_path}")
                if K_cropped is not None:
                    print(f"[è¿›ç¨‹ {os.getpid()}] å·²ä¿å­˜é»‘è¾¹è£å‰ªåå†…å‚: {k_cropped_path}")
            
            # ä¿å­˜ç•¸å˜ç³»æ•°
            d_suffix = "_8M_D.npy" if is_8M_camera else "_3M_D.npy"
            d_save_path = os.path.join(output_dir, f"camera_{direction}_scale_{scale:.2f}{d_suffix}")
            np.save(d_save_path, D)
            print(f"[è¿›ç¨‹ {os.getpid()}] å·²ä¿å­˜ç•¸å˜ç³»æ•°: {d_save_path}")
            
            # ç”ŸæˆåŸºç¡€JSONé…ç½®æ–‡ä»¶ï¼ˆå•ä¸ªæ–¹å‘çš„ï¼‰
            json_entries = []
            use_K = K_cropped if K_cropped is not None else (K_undistort if K_undistort is not None else K_original)
            
            # **ä¼ é€’ vehicle_type å’Œ logtime**
            camera_entry = generate_sensor_json_entry(
                folder_name=folder_name,
                direction=direction,
                K_matrix=use_K,
                translation=translation,
                rotation=rotation,
                sensor_type="camera",
                vehicle_type=vehicle_type,
                logtime=logtime
            )
            json_entries.append(camera_entry)
            
            # **ä¼ é€’ vehicle_type å’Œ logtime**
            json_entries.extend(generate_lidar_placeholder_entries(
                count=5, 
                vehicle_type=vehicle_type, 
                logtime=logtime
            ))
            
            json_filename = f"sensor_config_{direction}_scale_{scale:.2f}.json"
            json_path = os.path.join(output_dir, json_filename)
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(json_entries, f, indent=4, ensure_ascii=False)
            
            print(f"[è¿›ç¨‹ {os.getpid()}] å·²ç”ŸæˆåŸºç¡€ä¼ æ„Ÿå™¨é…ç½®JSON: {json_path}")
            
            # æ”¶é›†è¿™ä¸ªæ–¹å‘çš„ç›¸æœºæ¡ç›®ï¼Œç”¨äºåé¢çš„æ€»å’ŒJSON
            # **ä¼ é€’ vehicle_type å’Œ logtime**
            single_camera_entry = generate_sensor_json_entry(
                folder_name=folder_name,
                direction=direction,
                K_matrix=use_K,
                translation=translation,
                rotation=rotation,
                sensor_type="camera",
                vehicle_type=vehicle_type,
                logtime=logtime
            )
            direction_camera_entries[scale].append(single_camera_entry)
            
            # ç”Ÿæˆå„åˆ†è¾¨ç‡çš„JSONé…ç½®
            if enable_resolution_crop:
                for target_res in target_resolutions:
                    target_w, target_h = target_res
                    res_name = f"{target_w}x{target_h}"
                    res_dir = os.path.join(res_crop_dir, res_name)
                    
                    # åŠ è½½è¯¥åˆ†è¾¨ç‡çš„å†…å‚
                    res_k_suffix = "_8M_K_res_cropped.npy" if is_8M_camera else "_3M_K_res_cropped.npy"
                    res_k_path = os.path.join(res_dir, f"camera_{direction}_scale_{scale:.2f}_{res_name}{res_k_suffix}")
                    if os.path.exists(res_k_path):
                        K_res = np.load(res_k_path)
                        
                        # ç”Ÿæˆè¯¥åˆ†è¾¨ç‡çš„JSON
                        # **ä¼ é€’ vehicle_type å’Œ logtime**
                        res_json_entry = generate_sensor_json_entry(
                            folder_name=folder_name,
                            direction=f"{direction}_{res_name}",
                            K_matrix=K_res,
                            translation=translation,
                            rotation=rotation,
                            sensor_type="camera",
                            vehicle_type=vehicle_type,
                            logtime=logtime
                        )
                        # **ä¼ é€’ vehicle_type å’Œ logtime**
                        res_json_entries = [res_json_entry] + generate_lidar_placeholder_entries(
                            count=5, 
                            vehicle_type=vehicle_type, 
                            logtime=logtime
                        )
                        
                        res_json_path = os.path.join(res_dir, f"sensor_config_{direction}_scale_{scale:.2f}_{res_name}.json")
                        with open(res_json_path, 'w', encoding='utf-8') as f:
                            json.dump(res_json_entries, f, indent=4, ensure_ascii=False)
                        print(f"[è¿›ç¨‹ {os.getpid()}]   - å·²ç”Ÿæˆ{res_name}ä¼ æ„Ÿå™¨é…ç½®JSON: {res_json_path}")
            
            print(f"--- [è¿›ç¨‹ {os.getpid()}] scale = {scale} å¤„ç†å®Œæˆ ---")
        
        # è¾“å‡ºæ–¹å‘çº§åˆ«çš„æ€»ä½“ç»Ÿè®¡
        direction_elapsed = time.time() - direction_start_time
        total_processed = total_images * len(scales)
        direction_fps = total_processed / direction_elapsed if direction_elapsed > 0 else 0
        print(f"\n{'='*50}")
        print(f"âœ… æ–¹å‘ {direction} å…¨éƒ¨å¤„ç†å®Œæˆ:")
        print(f"   - æ€»å›¾ç‰‡æ•°: {total_images} å¼ ")
        print(f"   - å¤„ç†çš„scaleæ•°: {len(scales)}")
        print(f"   - æ€»å¤„ç†é‡: {total_processed} å¼ ")
        print(f"   - æ€»è€—æ—¶: {direction_elapsed:.2f}s ({direction_elapsed/60:.2f}åˆ†é’Ÿ)")
        print(f"   - å¹³å‡é€Ÿåº¦: {direction_fps:.2f} fps")
        print(f"{'='*50}\n")
            
    except Exception as e:
        print(f"\nâŒ [è¿›ç¨‹ {os.getpid()}] å¤„ç† {direction} æ–¹å‘æ—¶å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
    
    return direction_camera_entries

# **ä¿®æ”¹5ï¼šæ·»åŠ  logtime å‚æ•°**
def process_all_directions(
    base_path, params_dir, output_base, 
    scale_min=0.3, scale_max=0.8, scale_step=0.1, 
    crop_factor=0.02, 
    target_resolutions=None,
    enable_resolution_crop=True,
    vehicle_type="default", # è½¦è¾†ç±»å‹å‚æ•°
    logtime="no_time" # æ–°å¢ logtime å‚æ•°
):
    """
    å¹¶è¡Œå¤„ç†æ‰€æœ‰æ–¹å‘æ–‡ä»¶å¤¹
    """
    batch_start_time = time.time()
    
    # åˆå§‹åŒ–é»˜è®¤åˆ†è¾¨ç‡åˆ—è¡¨
    if target_resolutions is None:
        target_resolutions = [(1920, 1080), (1280, 720), (800, 600)]
    print(f"ç›®æ ‡åˆ†è¾¨ç‡åˆ—è¡¨: {target_resolutions}")
    print(f"æ˜¯å¦å¯ç”¨åˆ†è¾¨ç‡è£å‰ª: {enable_resolution_crop}")
    print(f"è½¦è¾†ç±»å‹: {vehicle_type}")
    print(f"LogTime: {logtime}") # æ‰“å°æ–°å¢å‚æ•°
    
    scales = np.arange(scale_min, scale_max + scale_step/2, scale_step)
    scales = [round(scale, 2) for scale in scales]
    print(f"å°†ä½¿ç”¨ä»¥ä¸‹scaleå€¼è¿›è¡Œå¤„ç†: {scales}")
    print(f"å¹¶è¡Œè¿›ç¨‹æ•°: {MAX_WORKERS}")
    
    # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ–¹å‘æ ‡è¯†çš„æ–‡ä»¶å¤¹
    direction_folders = find_direction_folders(base_path)
    if not direction_folders:
        print("æœªæ‰¾åˆ°ä»»ä½•åŒ…å«æ–¹å‘æ ‡è¯†çš„æ–‡ä»¶å¤¹ï¼")
        return
    
    print(f"\nğŸ¯ æ€»å…±æ‰¾åˆ° {len(direction_folders)} ä¸ªæ–¹å‘æ–‡ä»¶å¤¹")
    
    # ç”¨äºå­˜å‚¨æ‰€æœ‰æ–¹å‘çš„ç›¸æœºæ¡ç›®
    scale_camera_entries = defaultdict(list)
    
    # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œå¤„ç†æ¯ä¸ªæ–¹å‘æ–‡ä»¶å¤¹
    with ProcessPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_direction = {}
        for direction_info in direction_folders:
            future = executor.submit(
                process_single_direction,
                direction_info=direction_info,
                params_dir=params_dir,
                output_base=output_base,
                scales=scales,
                crop_factor=crop_factor,
                target_resolutions=target_resolutions,
                enable_resolution_crop=enable_resolution_crop,
                vehicle_type=vehicle_type, # ä¼ é€’ vehicle_type å‚æ•°
                logtime=logtime # ä¼ é€’ logtime å‚æ•°
            )
            future_to_direction[future] = direction_info[1]  # å­˜å‚¨æ–¹å‘åç§°
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in as_completed(future_to_direction):
            direction_name = future_to_direction[future]
            try:
                # è·å–è¯¥æ–¹å‘çš„å¤„ç†ç»“æœï¼ˆç›¸æœºæ¡ç›®å­—å…¸ï¼‰
                direction_entries = future.result()
                # åˆå¹¶åˆ°å…¨å±€çš„ç›¸æœºæ¡ç›®å­—å…¸ä¸­
                for scale, entries in direction_entries.items():
                    scale_camera_entries[scale].extend(entries)
                print(f"\n{'='*50}")
                print(f"æ–¹å‘ {direction_name} å¹¶è¡Œå¤„ç†å®Œæˆï¼")
                print(f"{'='*50}")
            except Exception as e:
                print(f"\n{'='*50}")
                print(f"æ–¹å‘ {direction_name} å¹¶è¡Œå¤„ç†å¤±è´¥: {str(e)}")
                print(f"{'='*50}")
    
    # ä¸ºæ¯ä¸ªscaleç”Ÿæˆæ€»å’ŒJSONæ–‡ä»¶
    print(f"\n{'='*50}")
    print("å¼€å§‹ç”Ÿæˆæ¯ä¸ªscaleçš„æ€»å’ŒJSONæ–‡ä»¶")
    print(f"{'='*50}")
    
    for scale in scales:
        if scale in scale_camera_entries and scale_camera_entries[scale]:
            # åˆ›å»ºæ€»å’ŒJSONçš„è¾“å‡ºç›®å½•ï¼ˆæ”¾åœ¨è¾“å‡ºæ ¹ç›®å½•ä¸‹ï¼‰
            combined_output_dir = os.path.join(output_base, f"combined_scales")
            os.makedirs(combined_output_dir, exist_ok=True)
            
            # **ä¼ é€’ vehicle_type å’Œ logtime**
            generate_scale_combined_json(
                combined_output_dir, 
                f"{scale:.2f}", 
                scale_camera_entries[scale],
                vehicle_type=vehicle_type,
                logtime=logtime
            )
        else:
            print(f"è­¦å‘Š: scale {scale} æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç›¸æœºæ¡ç›®ï¼Œè·³è¿‡ç”Ÿæˆæ€»å’ŒJSON")
    
    # è¾“å‡ºæ‰¹å¤„ç†ç»Ÿè®¡
    batch_elapsed = time.time() - batch_start_time
    print(f"\n{'='*60}")
    print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆç»Ÿè®¡:")
    print(f"   - å¤„ç†æ–¹å‘æ•°: {len(direction_folders)}")
    print(f"   - Scaleæ•°é‡: {len(scales)}")
    print(f"   - æ€»è€—æ—¶: {batch_elapsed:.2f}s ({batch_elapsed/60:.2f}åˆ†é’Ÿ)")
    print(f"   - å¹¶è¡Œè¿›ç¨‹æ•°: {MAX_WORKERS}")
    print(f"{'='*60}\n")

def generate_combined_json(
    output_base, 
    include_resolution_crops=False
):
    """
    ç”Ÿæˆç»¼åˆJSONæ–‡ä»¶ - æ ¹æ®æ–°çš„ç›®å½•ç»“æ„è°ƒæ•´
    """
    print("æ³¨æ„ï¼šç”±äºç›®å½•ç»“æ„å˜åŒ–ï¼Œéœ€è¦é‡æ–°å®ç°generate_combined_jsonå‡½æ•°")
    print("å½“å‰ç‰ˆæœ¬ä½¿ç”¨æ–°çš„æ€»å’ŒJSONç”Ÿæˆæ–¹å¼")
    
    # æŸ¥æ‰¾æ‰€æœ‰combined_scalesç›®å½•ä¸‹çš„JSONæ–‡ä»¶
    combined_dir = os.path.join(output_base, "combined_scales")
    if not os.path.exists(combined_dir):
        print(f"æœªæ‰¾åˆ°combined_scalesç›®å½•: {combined_dir}")
        return
    
    json_files = [f for f in os.listdir(combined_dir) if f.startswith("sensor_config_combined_scale_") and f.endswith(".json")]
    
    if not json_files:
        print("åœ¨combined_scalesç›®å½•ä¸‹æœªæ‰¾åˆ°ä»»ä½•æ€»å’ŒJSONæ–‡ä»¶")
        return
    
    # æ‰¾åˆ°æœ€æ–°çš„scaleæ–‡ä»¶
    # æå–scaleå€¼è¿›è¡Œæ¯”è¾ƒ
    def extract_scale(filename):
        match = re.search(r'_scale_(\d+\.\d+)\.json$', filename)
        return float(match.group(1)) if match else -1

    json_files.sort(key=extract_scale, reverse=True)
    latest_json = json_files[0]
    latest_json_path = os.path.join(combined_dir, latest_json)
    
    # å¤åˆ¶æœ€æ–°çš„æ€»å’ŒJSONä½œä¸ºä¸»é…ç½®æ–‡ä»¶
    main_config_path = os.path.join(output_base, "sensor_config_combined_latest.json")
    
    with open(latest_json_path, 'r', encoding='utf-8') as f:
        config_data = json.load(f)
    
    with open(main_config_path, 'w', encoding='utf-8') as f:
        json.dump(config_data, f, indent=4, ensure_ascii=False)
    
    print(f"å·²ç”Ÿæˆä¸»é…ç½®æ–‡ä»¶: {main_config_path} (åŸºäº {latest_json})")

def main():
    import time
    main_start_time = time.time()
    
    parser = argparse.ArgumentParser(description="å›¾åƒå»ç•¸å˜æ‰¹é‡å¤„ç†ç¨‹åºï¼ˆå¹¶è¡Œç‰ˆ + æ€»å’ŒJSONï¼‰")
    
    # 1. è·¯å¾„å‚æ•° (å·²ä¿®æ”¹)
    parser.add_argument(
        '--images', 
        type=str, 
        required=True, 
        help="å›¾åƒæ ¹ç›®å½• (å¯¹åº”åŸ base_images_path)"
    )
    parser.add_argument(
        '--params', 
        type=str, 
        required=True, 
        help="ç›¸æœºå†…å‚æ–‡ä»¶è·¯å¾„ (å¯¹åº”åŸ base_params_path)"
    )
    parser.add_argument(
        '--out', 
        type=str, 
        required=True, 
        help="è¾“å‡ºæ–‡ä»¶æ ¹ç›®å½• (å¯¹åº”åŸ output_path)"
    )
    
    # 2. æ–°å¢çš„å‚æ•° (å·²ä¿®æ”¹)
    parser.add_argument(
        '--vehicle',
        type=str,
        default="default",
        help="è½¦è¾†ç±»å‹æ ‡è¯†ï¼Œå¯ç”¨äºåŒºåˆ†ä¸åŒè½¦å‹çš„å†…å‚é…ç½®ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º'default'ï¼‰"
    )
    # **æ–°å¢çš„ logtime å‚æ•°**
    parser.add_argument(
        '--logtime',
        type=str,
        default="no_time",
        help="ç”¨äºæ ‡è¯†æ—¥å¿—æ–‡ä»¶æˆ–æ‰¹æ¬¡çš„å”¯ä¸€æ—¶é—´æˆ³/IDï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º'no_time'ï¼‰"
    )
    
    # åŸå§‹ä»£ç ä¸­çš„å›ºå®š/å¯é…ç½®å‚æ•°ï¼ˆå¯ä»¥è€ƒè™‘ä¹Ÿæ”¹ä¸ºå‘½ä»¤è¡Œå‚æ•°ï¼‰
    # è¿™é‡Œä¿æŒä¸ºå›ºå®šå€¼ï¼Œä½†ä½¿ç”¨æ–°çš„å˜é‡å
    parser.add_argument('--scale_min', type=float, default=0.2, help="Scaleæœ€å°å€¼")
    parser.add_argument('--scale_max', type=float, default=0.2, help="Scaleæœ€å¤§å€¼")
    parser.add_argument('--scale_step', type=float, default=0.1, help="Scaleæ­¥é•¿")
    parser.add_argument('--crop_factor', type=float, default=0.0, help="é»‘è¾¹è£å‰ªæ¯”ä¾‹ (0è¡¨ç¤ºä¸è£å‰ª)")
    parser.add_argument('--enable_res_crop', type=bool, default=False, help="æ˜¯å¦å¯ç”¨åˆ†è¾¨ç‡è£å‰ª")

    args = parser.parse_args()

    # ä»å‘½ä»¤è¡Œå‚æ•°è¯»å–è·¯å¾„
    base_images_path = args.images
    base_params_path = args.params
    output_path = args.out
    vehicle_type = args.vehicle # è½¦è¾†ç±»å‹å‚æ•°
    logtime = args.logtime # æ–°å¢ LogTime å‚æ•°

    # å…¶ä»–å›ºå®šé…ç½®
    SCALE_MIN = args.scale_min
    SCALE_MAX = args.scale_max
    SCALE_STEP = args.scale_step
    CROP_FACTOR = args.crop_factor
    ENABLE_RESOLUTION_CROP = args.enable_res_crop
    
    TARGET_RESOLUTIONS = [
        (1920, 1080),   # 1080P
        (2112, 768),    # 720P
    ]
    INCLUDE_RES_IN_COMBINED_JSON = True # ä¿æŒåŸæ ·ï¼Œä½†å®é™…é€»è¾‘ä¸­æ²¡æœ‰ä½¿ç”¨è¿™ä¸ªå˜é‡
    
    print("="*60)
    print("å›¾åƒå»ç•¸å˜æ‰¹é‡å¤„ç†ç¨‹åºï¼ˆå¹¶è¡Œç‰ˆ + æ€»å’ŒJSONï¼‰")
    print("="*60)
    print(f"è½¦è¾†ç±»å‹: {vehicle_type}") 
    print(f"LogTime: {logtime}") # æ‰“å°æ–°å¢å‚æ•°
    print(f"Scaleè®¾ç½®: æœ€å°å€¼={SCALE_MIN}, æœ€å¤§å€¼={SCALE_MAX}, æ­¥é•¿={SCALE_STEP}")
    print(f"é»‘è¾¹è£å‰ªè®¾ç½®: æ¯”ä¾‹={CROP_FACTOR}")
    print(f"åˆ†è¾¨ç‡è£å‰ªè®¾ç½®: {'å¯ç”¨' if ENABLE_RESOLUTION_CROP else 'ç¦ç”¨'}")
    print(f"ç›®æ ‡åˆ†è¾¨ç‡: {TARGET_RESOLUTIONS}")
    print(f"å›¾åƒæ ¹ç›®å½•: {base_images_path}")
    print(f"å‚æ•°è·¯å¾„: {base_params_path}")
    print(f"è¾“å‡ºè·¯å¾„: {output_path}")
    print(f"å¹¶è¡Œè¿›ç¨‹æ•°: {MAX_WORKERS}")
    print("="*60)
    print("æ–°çš„æ–‡ä»¶å¤„ç†é€»è¾‘ï¼š")
    print("1. è‡ªåŠ¨æ‰«ææ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹")
    print("2. åœ¨å­æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾åŒ…å«æ–¹å‘æ ‡è¯†çš„æ–‡ä»¶å¤¹")
    print("3. å¹¶è¡Œå¤„ç†å„ä¸ªæ–¹å‘æ–‡ä»¶å¤¹ï¼ˆä¸ä¿®æ”¹æ ¸å¿ƒå¤„ç†é€»è¾‘ï¼‰")
    print("4. æŒ‰ç…§åŸå§‹æ–‡ä»¶å¤¹ç»“æ„ä¿å­˜ç»“æœ")
    print("5. ä¸ºæ¯ä¸ªscaleç”Ÿæˆæ€»å’ŒJSONæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰ç›¸æœºæ–¹å‘å’Œé›·è¾¾ï¼‰")
    print("="*60)
    
    # æ‰¹é‡å¤„ç†
    process_all_directions(
        base_path=base_images_path, 
        params_dir=base_params_path, 
        output_base=output_path,
        scale_min=SCALE_MIN,
        scale_max=SCALE_MAX,
        scale_step=SCALE_STEP,
        crop_factor=CROP_FACTOR,
        target_resolutions=TARGET_RESOLUTIONS,
        enable_resolution_crop=ENABLE_RESOLUTION_CROP,
        vehicle_type=vehicle_type, # ä¼ é€’æ–°å¢å‚æ•°
        logtime=logtime # ä¼ é€’æ–°å¢å‚æ•°
    )
    
    # ç”Ÿæˆä¸»é…ç½®æ–‡ä»¶
    generate_combined_json(output_base=output_path)
    
    # è¾“å‡ºæ€»ä½“ç»Ÿè®¡
    total_elapsed = time.time() - main_start_time
    print("\n" + "="*60)
    print("âœ… æ‰€æœ‰å¤„ç†å·²å®Œæˆï¼")
    print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"   - æ€»è€—æ—¶: {total_elapsed:.2f}s ({total_elapsed/60:.2f}åˆ†é’Ÿ)")
    print(f"   - å¹¶è¡Œè¿›ç¨‹æ•°: {MAX_WORKERS}")
    print("="*60)
    print("è¾“å‡ºç›®å½•ç»“æ„ï¼š")
    print("save/")
    print("  â”œâ”€ combined_scales/")
    print("  â”‚  â”œâ”€ sensor_config_combined_scale_0.10.json  # æ¯ä¸ªscaleçš„æ€»å’ŒJSON")
    print("  â”‚  â”œâ”€ sensor_config_combined_scale_0.20.json")
    print("  â”‚  â””â”€ ...")
    print("  â”œâ”€ sensor_config_combined_latest.json  # ä¸»é…ç½®æ–‡ä»¶")
    print("  â”œâ”€ [çˆ¶æ–‡ä»¶å¤¹1]/")
    print("  â”‚  â”œâ”€ [åŸå§‹æ–¹å‘æ–‡ä»¶å¤¹1]/")
    print("  â”‚  â”‚  â”œâ”€ [æ–¹å‘]/")
    print("  â”‚  â”‚  â”‚  â”œâ”€ scale_xx/")
    print("  â”‚  â”‚  â”‚  â”‚  â”œâ”€ [å›¾åƒ]_undistorted.xxx")
    print("  â”‚  â”‚  â”‚  â”‚  â”œâ”€ camera_xxx_K_*.npy")
    print("  â”‚  â”‚  â”‚  â”‚  â”œâ”€ sensor_config_[æ–¹å‘]_scale_xx.json  # å•ä¸ªæ–¹å‘JSON")
    print("  â”‚  â”‚  â”‚  â”‚  â””â”€ resolution_crops/")
    print("  â”‚  â”œâ”€ [åŸå§‹æ–¹å‘æ–‡ä»¶å¤¹2]/")
    print("  â”‚  â”‚  â””â”€ ...")
    print("  â”œâ”€ [çˆ¶æ–‡ä»¶å¤¹2]/")
    print("  â”‚  â””â”€ ...")
    print("="*60)

if __name__ == '__main__':
    # Windowsç³»ç»Ÿéœ€è¦æ·»åŠ è¿™è¡Œä»£ç ï¼ˆå¯é€‰ï¼‰
    # multiprocessing.freeze_support()
    
    main()